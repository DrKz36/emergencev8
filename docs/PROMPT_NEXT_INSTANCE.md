# Guide de reprise pour la prochaine session

**Date de mise √† jour**: 2025-10-15 (session de correction)
**Version pr√©c√©dente**: Voir historique Git

## üéØ R√©sum√© ex√©cutif

Deux probl√®mes ont √©t√© **analys√©s et corrig√©s** dans cette session :

1. **Notifications d'inactivit√©**: ‚úÖ **CORRIG√â** - Le payload backend √©tait incorrect
2. **M√©triques Prometheus**: ‚úÖ **CODE OK** - N√©cessite juste un red√©ploiement

**Statut**: üß™ **PR√äT POUR TEST LOCAL** ‚Üí Puis d√©ploiement si tests OK

## Contexte de la session actuelle (2025-10-15)

### Ce qui a √©t√© diagnostiqu√© et corrig√©

1. **Probl√®me de notifications d'inactivit√©** - CAUSE IDENTIFI√âE ET CORRIG√âE ‚úÖ
2. **Probl√®me de m√©triques Prometheus** - CODE D√âJ√Ä CORRECT ‚úÖ

## ‚úÖ Corrections appliqu√©es (session actuelle)

### Correction 1: Payload des notifications d'inactivit√©

**Fichier**: `src/backend/core/session_manager.py`

**Probl√®me identifi√©**: Le format du payload ne correspondait pas au format attendu par le frontend.

**AVANT (ligne 158)** - ‚ùå INCORRECT:
```python
{
    "type": "inactivity_warning",  # ‚ùå Mauvais champ
    "message": "Votre session sera d√©connect√©e...",
    "remaining_seconds": 30
}
```

**APR√àS (ligne 169-174)** - ‚úÖ CORRIG√â:
```python
{
    "notification_type": "inactivity_warning",  # ‚úÖ Correct
    "message": "Votre session sera d√©connect√©e...",
    "remaining_seconds": 30,
    "duration": 5000  # ‚úÖ Ajout√© pour affichage
}
```

### Correction 2: Logs de debug ajout√©s

**Nouveaux logs** pour diagnostiquer le comportement:
- **Ligne 125**: Nombre de sessions actives v√©rifi√©es
- **Ligne 137-140**: √âtat d'inactivit√© de chaque session (dur√©e, seuils)
- **Ligne 145, 152**: Marquage pour nettoyage/avertissement
- **Ligne 175-177**: Confirmation d'envoi de notification avec payload complet
- **Ligne 179**: Warning si ConnectionManager n'est pas disponible

**Exemple de logs attendus**:
```
[Inactivity Check] 1 session(s) active(s) √† v√©rifier
[Inactivity Check] Session 12345678... inactive depuis 150s (seuil avertissement: 150s, seuil timeout: 180s)
[Inactivity Check] Session 12345678... avertissement d√©j√† envoy√©: False
[Inactivity Check] Session 12345678... marqu√©e pour avertissement
[Notification] Envoi notification inactivit√© √† 12345678... payload: {'notification_type': 'inactivity_warning', ...}
[Notification] Notification inactivit√© envoy√©e avec succ√®s √† 12345678...
```

### √âtat du code Prometheus (D√âJ√Ä CORRECT)

**Fichier**: `src/backend/features/metrics/router.py:14`

Le code est **d√©j√† correct** depuis une session pr√©c√©dente:
```python
METRICS_ENABLED = os.getenv("CONCEPT_RECALL_METRICS_ENABLED", "true").lower() == "true"
```

**Pas de modification n√©cessaire** - Juste besoin d'un red√©ploiement.

## üî¨ Diagnostic complet effectu√©

### Frontend WebSocket Handler (D√âJ√Ä CORRECT)
- Fichier: `src/frontend/core/websocket.js:356-377`
- Handler `ws:system_notification` correctement impl√©ment√©
- Attend bien `notification_type` (pas `type`)
- G√®re le champ `duration` pour l'affichage

### Backend SessionManager (CORRIG√â DANS CETTE SESSION)
- Fichier: `src/backend/core/session_manager.py`
- Configuration timeout: 3 minutes (ligne 21)
- Intervalle de nettoyage: 30 secondes (ligne 22)
- Avertissement: 30 secondes avant timeout (ligne 23)
- **Payload maintenant corrig√©** (ligne 169-174)
- **Logs de debug ajout√©s** pour tra√ßabilit√©

### Backend Prometheus (D√âJ√Ä CORRECT AVANT)
- Fichier: `src/backend/features/metrics/__init__.py` existe
- Fichier: `src/backend/features/metrics/router.py` avec default="true"
- Montage: `src/backend/main.py:336` sans pr√©fixe /api

## üöÄ T√¢ches pour la prochaine session

### PRIORIT√â 1: Test local OBLIGATOIRE ‚ö†Ô∏è

**IMPORTANT**: Ne pas d√©ployer sur Cloud Run avant d'avoir valid√© les corrections localement.

```bash
# V√©rifier les variables d'environnement sur Cloud Run
gcloud run services describe emergence-app --region=europe-west1 --format='value(spec.template.spec.containers[0].env)'

# Si CONCEPT_RECALL_METRICS_ENABLED n'est pas d√©finie, l'ajouter
gcloud run services update emergence-app \
  --region=europe-west1 \
  --set-env-vars CONCEPT_RECALL_METRICS_ENABLED=true

# Tester l'endpoint
curl -s https://emergence-app-486095406755.europe-west1.run.app/metrics | head -20
```

### √âtape 2: Diagnostiquer les notifications d'inactivit√©

```bash
# 1. V√©rifier que le nouveau code frontend est d√©ploy√©
curl -s https://emergence-app-486095406755.europe-west1.run.app/src/frontend/core/websocket.js | grep -A 10 "ws:system_notification"

# 2. V√©rifier les logs backend pour voir si les notifications sont envoy√©es
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app AND textPayload=~'inactivity_warning'" --limit 20 --project emergence-469005

# 3. V√©rifier les logs de la boucle de nettoyage
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app AND textPayload=~'cleanup|SessionManager'" --limit 50 --project emergence-469005
```

### √âtape 3: Tester localement d'abord

```bash
# Build local
cd c:/dev/emergenceV8
docker build -t emergence-app:test-local .

# Run local
docker run -p 8080:8080 \
  -e CONCEPT_RECALL_METRICS_ENABLED=true \
  -e SESSION_INACTIVITY_TIMEOUT_MINUTES=3 \
  emergence-app:test-local

# Tester l'endpoint metrics
curl -s http://localhost:8080/metrics | head -20

# Tester une session et attendre 3 minutes d'inactivit√©
```

### √âtape 4: V√©rifier le code du SessionManager

**Points √† v√©rifier**:

1. Le `last_activity_at` est-il bien mis √† jour lors des requ√™tes ?
2. La boucle `_cleanup_inactive_sessions_loop` s'ex√©cute-t-elle r√©ellement ?
3. Les sessions sont-elles stock√©es correctement dans `active_sessions` ?

**Code √† examiner** (`src/backend/core/session_manager.py`):
- Ligne 101-148: La boucle de nettoyage
- Ligne 154-162: L'envoi des notifications
- M√©thode pour mettre √† jour `last_activity_at` (chercher o√π elle est appel√©e)

### √âtape 5: Ajouter des logs de debug

Si le probl√®me persiste, ajouter des logs temporaires pour comprendre ce qui se passe :

```python
# Dans session_manager.py, dans la boucle de nettoyage
async def _cleanup_inactive_sessions_loop(self):
    while self._is_running:
        try:
            now = datetime.now(timezone.utc)
            logger.info(f"[DEBUG] Cleanup loop - Active sessions: {len(self.active_sessions)}")

            for session_id, session in list(self.active_sessions.items()):
                inactive_duration = now - session.last_activity_at
                logger.info(f"[DEBUG] Session {session_id} inactive for {inactive_duration.total_seconds()}s")
                # ... reste du code
```

## Fichiers √† consulter

### Backend
- `src/backend/core/session_manager.py` - Gestion des sessions et timeout
- `src/backend/features/metrics/router.py` - Endpoint Prometheus
- `src/backend/features/metrics/__init__.py` - Fichier cr√©√© pour import Python
- `src/backend/main.py:336` - Montage du router metrics
- `src/backend/core/websocket.py:252-258` - M√©thode `send_system_message`

### Frontend
- `src/frontend/core/websocket.js:355-377` - Handler des notifications syst√®me
- `src/frontend/shared/notifications.js` - Syst√®me de toasts

## Images Docker disponibles

Plusieurs images ont √©t√© build√©es :
- `emergence-app:timeout-fix`
- `emergence-app:v2-enhanced`
- `emergence-app:metrics-fix`
- `emergence-app:metrics-fix-v2`
- `emergence-app:inactivity-notif` (derni√®re)

**R√©vision actuellement en production**: `emergence-app-00345-c7j`

## Commandes utiles

```bash
# Lister les r√©visions Cloud Run
gcloud run revisions list --service=emergence-app --region=europe-west1

# Basculer le trafic vers une r√©vision sp√©cifique
gcloud run services update-traffic emergence-app \
  --region=europe-west1 \
  --to-revisions=emergence-app-00346-xxx=100

# Voir les logs en temps r√©el
gcloud logging tail "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app" --project emergence-469005

# Tester l'endpoint metrics
curl -s https://emergence-app-486095406755.europe-west1.run.app/metrics

# Tester avec un header sp√©cifique
curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" \
  https://emergence-app-486095406755.europe-west1.run.app/metrics
```

## Questions √† poser pour d√©bugger

1. **Le SessionManager d√©tecte-t-il l'inactivit√© ?**
   - Chercher dans les logs: "inactive for more than"
   - V√©rifier que `last_activity_at` est bien mis √† jour

2. **Les messages WebSocket sont-ils envoy√©s ?**
   - Chercher dans les logs: "Sending inactivity warning"
   - V√©rifier que `connection_manager.send_system_message` est appel√©

3. **Le frontend re√ßoit-il les messages ?**
   - Ouvrir la console du navigateur
   - Filtrer sur "WebSocket" et "system_notification"
   - V√©rifier que le handler est bien ex√©cut√©

4. **Les toasts fonctionnent-ils ?**
   - Tester manuellement: `window.eventBus.emit('ui:toast', {kind: 'warning', text: 'Test'})`

## Ressources

- Documentation compl√®te: `docs/ISSUES_INACTIVITY_METRICS.md`
- Git status au moment de la session: main branch avec modifications non commit√©es
- Service Cloud Run: `emergence-app` (region: europe-west1)
- URL de production: https://emergence-app-486095406755.europe-west1.run.app

## Approche recommand√©e

1. **Commencer par les m√©triques Prometheus** (plus simple √† d√©bugger)
2. **Tester localement** pour valider que le code fonctionne
3. **Ajouter des logs de debug** dans le SessionManager
4. **D√©ployer une nouvelle r√©vision** avec les logs de debug
5. **Monitorer les logs en temps r√©el** pendant un test d'inactivit√©

---

**Note importante**: Ne pas oublier de vider le cache du navigateur (Ctrl+Shift+R) apr√®s chaque d√©ploiement frontend pour voir les changements JavaScript.
