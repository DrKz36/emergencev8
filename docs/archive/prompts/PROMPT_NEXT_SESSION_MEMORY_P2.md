# üöÄ Prompt Session Suivante - Impl√©mentation M√©moire Phase P2

**Date cr√©ation** : 2025-10-10
**Contexte** : Suite session audit P0 - Tous gaps critiques r√©solus
**Objectif** : Continuer impl√©mentation m√©moire selon priorit√©s

---

## üìã Contexte Projet

Tu es **Claude Code**, agent IA sp√©cialis√© en d√©veloppement backend/frontend pour **EMERGENCE V8**, une plateforme multi-agents (Anima, Neo, Nexus) avec syst√®me m√©moire STM/LTM avanc√©.

**Stack technique** :
- Backend : Python 3.11 + FastAPI + SQLite + ChromaDB (vectoriel)
- Frontend : Vanilla JS + Vite
- Tests : pytest + asyncio
- Monitoring : Prometheus + m√©triques custom

---

## ‚úÖ Travail D√©j√† Accompli (Phase P0 + P1)

### Phase P1 (Compl√©t√©e ‚úÖ)
- ‚úÖ MemoryTaskQueue async (d√©portation hors boucle WS)
- ‚úÖ PreferenceExtractor modulaire (filtrage lexical + LLM)
- ‚úÖ 5 m√©triques Prometheus pr√©f√©rences
- ‚úÖ Tests : 20/20 pr√©f√©rences + 8/8 extraction

### Phase P0 (Compl√©t√©e ‚úÖ)
- ‚úÖ **Gap #2** : Persistance pr√©f√©rences ChromaDB impl√©ment√©e
- ‚úÖ **Gap #1** : Consolidation threads archiv√©s automatique
  - Endpoint `/api/memory/consolidate-archived`
  - Hook archivage ‚Üí TaskQueue `consolidate_thread`
  - Tests : 10/10 consolidation archiv√©s
- üü° **Gap #3** : Architecture hybride sessions/threads (P2 refactoring)

**Documentation compl√®te** :
- [P0_GAPS_RESOLUTION_STATUS.md](docs/validation/P0_GAPS_RESOLUTION_STATUS.md)
- [MEMORY_LTM_GAPS_ANALYSIS.md](docs/architecture/MEMORY_LTM_GAPS_ANALYSIS.md)
- [MEMORY_CAPABILITIES.md](docs/MEMORY_CAPABILITIES.md)

---

## üéØ Mission Principale : Phase P2 - Optimisations Performance M√©moire

**Plan d√©taill√©** : [MEMORY_P2_PERFORMANCE_PLAN.md](docs/optimizations/MEMORY_P2_PERFORMANCE_PLAN.md)

### Priorit√©s par Sprint

#### üèÜ **Sprint 1 : Indexation & Cache (2-3 jours) - PRIORIT√â MAX**

**Probl√®me** :
- Requ√™tes ChromaDB lentes (100-200ms) bloquent g√©n√©ration r√©ponses
- Pr√©f√©rences recharg√©es √† chaque message (gaspillage)
- Pas d'index sur m√©tadonn√©es cl√©s (user_id, type, confidence)

**Actions** :
1. **Cr√©er index ChromaDB** (`src/backend/features/memory/vector_service.py`)
   ```python
   # Ajouter dans get_or_create_collection()
   collection.create_index(field="user_id", index_type="exact")
   collection.create_index(field="type", index_type="exact")
   collection.create_index(field="confidence", index_type="range")
   ```

2. **Cache pr√©f√©rences d√©j√† impl√©ment√©** ‚úÖ
   - `_fetch_active_preferences_cached()` existe ([memory_ctx.py:132-149](src/backend/features/chat/memory_ctx.py#L132-L149))
   - TTL 5 min, metrics Prometheus int√©gr√©es
   - **Action** : V√©rifier utilisation effective (grep `_fetch_active_preferences_cached`)

3. **Batch prefetch concepts LTM**
   - Charger top 20 concepts user au handshake WS
   - Stocker dans SessionManager pour r√©utilisation
   - √âviter requ√™tes r√©p√©t√©es pendant conversation

4. **Tests performance**
   ```python
   # tests/backend/features/test_memory_performance.py (√† cr√©er)
   async def test_preference_cache_hit_rate():
       # Target: >80% hit rate apr√®s warmup

   async def test_chromadb_query_latency():
       # Target: <50ms avec index (vs 200ms sans)

   async def test_batch_prefetch_vs_incremental():
       # Target: 5x faster (1 query vs 10)
   ```

**Livrables** :
- Index ChromaDB op√©rationnels
- Cache pr√©f√©rences valid√© (hit rate >80%)
- Batch prefetch impl√©ment√©
- Tests performance (3 tests min)
- M√©triques Prometheus : `memory_query_duration_seconds`, `memory_cache_hit_rate`

---

#### üéØ **Sprint 2 : Proactive Hints Backend (2-3 jours)**

**Objectif** : Agents sugg√®rent actions bas√©es sur pr√©f√©rences/intentions captur√©es

**Architecture** :
```
PreferenceExtractor (existant)
    ‚Üì
ProactiveHintEngine (nouveau)
    ‚îú‚îÄ> R√®gles m√©tier (if topic="language" AND confidence>0.7 ‚Üí suggest)
    ‚îú‚îÄ> Scoring pertinence contexte actuel
    ‚îî‚îÄ> G√©n√©ration hints JSON
         ‚Üì
WebSocket event ws:proactive_hint
    ‚Üì
Frontend affiche suggestion
```

**Impl√©mentation** :

1. **Cr√©er `ProactiveHintEngine`** (`src/backend/features/memory/proactive_hints.py`)
   ```python
   class ProactiveHintEngine:
       def __init__(self, vector_service, db_manager):
           self.vector_service = vector_service
           self.db = db_manager

       async def generate_hints(
           self,
           user_id: str,
           current_context: dict
       ) -> List[ProactiveHint]:
           """
           Analyse pr√©f√©rences user + contexte actuel
           Retourne suggestions pertinentes
           """
           # 1. Fetch pr√©f√©rences haute confidence (>0.7)
           # 2. Match avec contexte conversation (topics similaires)
           # 3. Score pertinence (0-1)
           # 4. G√©n√©rer hints (top 3 max)

   @dataclass
   class ProactiveHint:
       id: str
       type: str  # "preference_reminder" | "intent_followup" | "constraint_warning"
       title: str
       message: str
       action_label: Optional[str]
       action_payload: Optional[dict]
       relevance_score: float
       source_preference_id: str
   ```

2. **Int√©grer dans ChatService** (`src/backend/features/chat/service.py`)
   ```python
   # Apr√®s g√©n√©ration r√©ponse agent, avant envoi WS
   if user_preferences_enabled:
       hints = await proactive_engine.generate_hints(
           user_id=user_id,
           current_context={
               "topic": extract_topic(message),
               "agent": agent_id,
               "conversation_context": last_5_messages
           }
       )

       if hints:
           await connection_manager.send_personal_message(
               session_id=session_id,
               message={
                   "type": "ws:proactive_hint",
                   "hints": [h.to_dict() for h in hints[:3]]  # Max 3
               }
           )
   ```

3. **Tests** (`tests/backend/features/test_proactive_hints.py`)
   ```python
   async def test_hint_generation_preference_match()
   async def test_hint_relevance_scoring()
   async def test_hint_max_limit_3()
   async def test_hint_websocket_emission()
   ```

**Livrables** :
- `ProactiveHintEngine` fonctionnel
- Int√©gration ChatService
- Event WS `ws:proactive_hint`
- Tests unitaires (4 min)
- M√©triques : `memory_proactive_hints_generated_total{type}`

---

#### üé® **Sprint 3 : Proactive Hints UI + Dashboard M√©moire (2-3 jours)**

**Frontend** :

1. **Composant Hints** (`src/frontend/features/memory/proactive-hints.js`)
   ```javascript
   class ProactiveHintsUI {
       init() {
           this.container = document.getElementById('proactive-hints-container');
           EventBus.on('ws:proactive_hint', (data) => {
               this.displayHints(data.hints);
           });
       }

       displayHints(hints) {
           // Badge discret coin sup√©rieur droit
           // Clic ‚Üí dropdown suggestions
           // Actions : "Appliquer", "Ignorer", "Rappeler plus tard"
       }
   }
   ```

2. **Dashboard M√©moire** (`src/frontend/features/memory/memory-dashboard.js`)
   ```javascript
   // Page d√©di√©e /memory-dashboard
   class MemoryDashboard {
       async loadData() {
           // 1. Pr√©f√©rences captur√©es (table triable)
           // 2. Concepts LTM (nuage tags pond√©r√©)
           // 3. Threads archiv√©s consolid√©s (timeline)
           // 4. Stats : taux rappel, pr√©cision extraction
       }
   }
   ```

3. **Int√©gration Menu**
   ```html
   <!-- src/frontend/index.html -->
   <nav>
       <a href="/memory-dashboard">üß† Ma M√©moire</a>
   </nav>
   ```

**Livrables** :
- UI hints proactifs fonctionnelle
- Dashboard m√©moire complet
- Tests E2E (Playwright)
- Documentation utilisateur

---

## üêõ Bugs D√©tect√©s √† Corriger (Priorit√© Haute)

### üî¥ Bug #1 : Co√ªts Gemini = 0 (Sous-estimation 70-80%)

**Localisation** : [llm_stream.py:178-180](src/backend/features/chat/llm_stream.py#L178-L180)

**Probl√®me** :
```python
# Ligne 178-180 - INCORRECT
cost_info_container.setdefault("input_tokens", 0)   # ‚Üê Toujours 0
cost_info_container.setdefault("output_tokens", 0)  # ‚Üê Toujours 0
cost_info_container.setdefault("total_cost", 0.0)   # ‚Üê Toujours 0
```

**Cause** : Google Generative AI ne retourne PAS `usage` en streaming, contrairement √† OpenAI.

**Solution** :
```python
async def _get_gemini_stream(self, model, system_prompt, history, cost_info_container):
    _model = genai.GenerativeModel(model_name=model, system_instruction=system_prompt)

    # COUNT TOKENS INPUT (avant g√©n√©ration)
    prompt_parts = [system_prompt] + [msg.get("content", "") for msg in history]
    input_tokens = _model.count_tokens(prompt_parts).total_tokens

    # G√©n√©ration streaming
    resp = await _model.generate_content_async(history, stream=True, ...)
    full_response_text = ""
    async for chunk in resp:
        text = getattr(chunk, "text", None)
        if text:
            full_response_text += text
            yield text

    # COUNT TOKENS OUTPUT (apr√®s g√©n√©ration)
    output_tokens = _model.count_tokens(full_response_text).total_tokens

    # CALCUL CO√õT
    pricing = MODEL_PRICING.get(model, {"input": 0, "output": 0})
    cost_info_container.update({
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_cost": (input_tokens * pricing["input"]) + (output_tokens * pricing["output"])
    })
```

**Validation** :
```bash
# Apr√®s fix
python -m pytest tests/backend/features/test_llm_costs.py -v
sqlite3 emergence.db "SELECT model, total_cost FROM costs WHERE model LIKE '%gemini%' LIMIT 5;"
# V√©rifier total_cost > 0
```

**Impact** : Critique - Gemini = 70-80% du trafic, sous-estimation massive co√ªts.

---

### üü° Bug #2 : Gap #3 Architecture Hybride (Refactoring P2)

**Probl√®me** : Mode batch `tend_the_garden()` sans `thread_id` utilise table `sessions` legacy au lieu de `threads` modernes.

**Code actuel** :
```python
# gardener.py:549-568
sessions = await self._fetch_recent_sessions(limit=consolidation_limit)
for s in sessions:
    history = self._extract_history(s.get("session_data"))  # ‚Üê JSON legacy
```

**Solution recommand√©e** : Migrer vers threads
```python
# Nouveau mode batch (√† impl√©menter)
threads = await queries.get_threads(
    db,
    user_id=user_id,
    include_archived=False,  # Seulement actifs en batch
    limit=consolidation_limit
)

for thread in threads:
    await self._tend_single_thread(
        thread_id=thread["id"],
        session_id=thread["session_id"],
        user_id=thread["user_id"]
    )
```

**D√©cision requise** :
- Option A : Migration compl√®te (recommand√©, 2-3 jours)
- Option B : Maintenir hybride + sync explicite

**Action** : Cr√©er ADR (Architecture Decision Record) et soumettre √† validation avant impl√©mentation.

---

## üìä M√©triques Succ√®s Phase P2

| Objectif | KPI Actuel | Target P2 | Outil Mesure |
|----------|-----------|-----------|--------------|
| **Latence requ√™tes ChromaDB** | 100-200ms | <50ms | `memory_query_duration_seconds` |
| **Cache hit rate pr√©f√©rences** | 0% (pas utilis√©) | >80% | `memory_cache_hit_rate` |
| **Hints proactifs g√©n√©r√©s** | 0 | >5/jour/user | `memory_proactive_hints_generated_total` |
| **Pr√©cision extraction pr√©f√©rences** | ~75% | >85% | Tests corpus annot√©s |
| **Threads archiv√©s consolid√©s** | 0% | 100% | SQL vs ChromaDB count |

---

## üöÄ Comment D√©marrer la Session

### 1. Relire le Contexte (10 min)
```bash
# Lire ces 3 docs dans l'ordre
cat docs/validation/P0_GAPS_RESOLUTION_STATUS.md
cat docs/optimizations/MEMORY_P2_PERFORMANCE_PLAN.md
cat docs/cockpit/COCKPIT_GAPS_AND_FIXES.md
```

### 2. V√©rifier l'Environnement (5 min)
```bash
# Backend
python -m pytest tests/backend/features/ -k "memory" -v --tb=short
# Doit afficher : 30+ tests passants

# V√©rifier ChromaDB
python -c "from src.backend.features.memory.vector_service import VectorService; print('‚úÖ VectorService OK')"

# V√©rifier TaskQueue
python -c "from src.backend.features.memory.task_queue import MemoryTaskQueue; print('‚úÖ TaskQueue OK')"
```

### 3. Prioriser les Actions
**Ordre recommand√©** :
1. üî¥ **URGENT** : Fixer Bug #1 (co√ªts Gemini) ‚Üí 1-2h
2. üèÜ **Sprint 1** : Indexation ChromaDB + validation cache ‚Üí 1-2 jours
3. üéØ **Sprint 2** : Proactive hints backend ‚Üí 2-3 jours
4. üé® **Sprint 3** : Proactive hints UI + dashboard ‚Üí 2-3 jours
5. üü° **Refactoring** : Gap #3 architecture (apr√®s validation FG)

### 4. Cr√©er Todo List
```javascript
// Utiliser TodoWrite pour tracker
[
  {
    "content": "üî¥ URGENT - Fixer co√ªts Gemini (count_tokens manquant)",
    "status": "in_progress",
    "activeForm": "Fix calcul co√ªts Gemini"
  },
  {
    "content": "Cr√©er index ChromaDB (user_id, type, confidence)",
    "status": "pending",
    "activeForm": "Cr√©ation index ChromaDB"
  },
  {
    "content": "Valider cache pr√©f√©rences (_fetch_active_preferences_cached)",
    "status": "pending",
    "activeForm": "Validation cache pr√©f√©rences"
  },
  // ... etc
]
```

### 5. Commencer par le Bug Critique
```python
# Ouvrir llm_stream.py et chercher _get_gemini_stream
# Appliquer le fix document√© ci-dessus
# Lancer tests
python -m pytest tests/backend/features/test_llm_costs.py -v -k gemini
```

---

## üìÅ Fichiers Cl√©s √† Conna√Ætre

### Backend M√©moire
- `src/backend/features/memory/analyzer.py` - MemoryAnalyzer + PreferenceExtractor
- `src/backend/features/memory/gardener.py` - MemoryGardener (consolidation)
- `src/backend/features/memory/vector_service.py` - ChromaDB + SBERT
- `src/backend/features/memory/task_queue.py` - MemoryTaskQueue (async)
- `src/backend/features/memory/router.py` - Endpoints API m√©moire
- `src/backend/features/chat/memory_ctx.py` - MemoryContextBuilder (injection RAG)

### Backend Chat/LLM
- `src/backend/features/chat/service.py` - ChatService (orchestration)
- `src/backend/features/chat/llm_stream.py` - üî¥ **BUG ICI** (co√ªts Gemini)
- `src/backend/features/chat/pricing.py` - MODEL_PRICING (tarifs)

### Frontend
- `src/frontend/features/memory/memory.js` - UI m√©moire existante
- `src/frontend/features/chat/chat-ui.js` - Chat (o√π int√©grer hints)
- `src/frontend/core/event-bus.js` - EventBus (√©couter ws:proactive_hint)

### Tests
- `tests/backend/features/test_memory_preferences_persistence.py` - 20 tests ‚úÖ
- `tests/backend/features/test_memory_archived_consolidation.py` - 10 tests ‚úÖ
- `tests/backend/features/test_preference_extraction_context.py` - 8 tests ‚úÖ

### Documentation
- `docs/validation/P0_GAPS_RESOLUTION_STATUS.md` - √âtat P0 (cr√©√© cette session)
- `docs/optimizations/MEMORY_P2_PERFORMANCE_PLAN.md` - Plan P2 d√©taill√©
- `docs/architecture/MEMORY_LTM_GAPS_ANALYSIS.md` - Analyse gaps initiale
- `docs/MEMORY_CAPABILITIES.md` - Capacit√©s syst√®me
- `docs/memory-roadmap.md` - Roadmap globale

---

## üéØ Objectifs de la Session

**Minimum Viable** (1 journ√©e) :
- ‚úÖ Bug #1 co√ªts Gemini fix√© + test√©
- ‚úÖ Index ChromaDB cr√©√©s
- ‚úÖ Cache pr√©f√©rences valid√© (hit rate mesur√©)
- ‚úÖ Tests performance (3 tests min)

**Optimal** (2-3 jours) :
- ‚úÖ Tout le Sprint 1 compl√©t√©
- ‚úÖ ProactiveHintEngine backend d√©marr√©
- ‚úÖ Event WS `ws:proactive_hint` fonctionnel

**Stretch Goal** (1 semaine) :
- ‚úÖ Sprint 1 + 2 + 3 complets
- ‚úÖ Dashboard m√©moire UI op√©rationnel
- ‚úÖ Tests E2E Playwright
- ‚úÖ M√©triques Prometheus compl√®tes

---

## ‚ö†Ô∏è Points d'Attention

### Performance
- **ChromaDB** : Indexation = gains 4-5x latence (200ms ‚Üí 50ms)
- **Cache** : Hit rate >80% critique pour UX fluide
- **Batch prefetch** : √âviter N+1 queries (1 batch vs 10 incr√©mentales)

### Architecture
- **Gap #3** : NE PAS modifier sans validation FG (risque breaking changes)
- **ProactiveHints** : Max 3 hints simultan√©s (√©viter spam)
- **WebSocket** : Hints envoy√©s APR√àS r√©ponse agent (pas avant)

### Tests
- **Toujours** lancer tests avant commit : `python -m pytest tests/backend/features/ -k memory -v`
- **Performance** : Ajouter benchmarks (pytest-benchmark)
- **E2E** : Utiliser Playwright pour UI hints

### M√©triques
- **Prometheus** : Toutes nouvelles m√©triques doivent avoir buckets adapt√©s
- **Logs** : Logger niveau INFO pour hints g√©n√©r√©s (debug traces)

---

## üìû Ressources & Support

### Documentation Externe
- ChromaDB indexing : https://docs.trychroma.com/guides/performance#indexing
- Prometheus histograms : https://prometheus.io/docs/practices/histograms/
- pytest-asyncio : https://pytest-asyncio.readthedocs.io/

### Commandes Utiles
```bash
# Tests m√©moire complets
python -m pytest tests/backend/features/ -k memory -v --tb=short

# V√©rifier m√©triques Prometheus
curl http://localhost:8000/api/metrics | grep memory_

# Inspecter ChromaDB
python scripts/inspect_chromadb.py --collection emergence_knowledge --limit 10

# Profiling performance
python -m cProfile -o profile.stats src/backend/main.py
python -m pstats profile.stats
```

---

## ‚úÖ Checklist Avant de Terminer la Session

### Code
- [ ] Bug #1 (co√ªts Gemini) fix√© et test√©
- [ ] Index ChromaDB cr√©√©s et valid√©s
- [ ] Cache pr√©f√©rences hit rate >80%
- [ ] Tests performance ajout√©s (min 3)
- [ ] Tous tests passent (pytest -v)

### Documentation
- [ ] Mettre √† jour [memory-roadmap.md](docs/memory-roadmap.md) avec avancement
- [ ] Documenter nouvelles m√©triques Prometheus
- [ ] Cr√©er ADR pour Gap #3 si abord√©
- [ ] Mettre √† jour [docs/passation.md](docs/passation.md)

### Git
- [ ] Commits atomiques avec messages clairs
- [ ] Branch `feat/memory-p2-sprint1` (ou √©quivalent)
- [ ] Push r√©guliers (√©viter perte travail)
- [ ] PR description d√©taill√©e si merge

### Handover
- [ ] Cr√©er `PROMPT_NEXT_SESSION_*.md` pour session suivante
- [ ] Lister blocages/d√©cisions en attente
- [ ] Documenter TODO restants avec priorit√©s

---

## üöÄ Let's Go!

**Premi√®re action recommand√©e** :
```bash
# 1. Lire statut P0
cat docs/validation/P0_GAPS_RESOLUTION_STATUS.md

# 2. Fixer bug critique
code src/backend/features/chat/llm_stream.py
# ‚Üí Chercher ligne 178, appliquer fix count_tokens

# 3. Tester
python -m pytest tests/backend/features/ -k gemini -v

# 4. Cr√©er todo list
# Utiliser TodoWrite pour tracker progression
```

**Bon courage ! üí™**

---

**Version** : 1.0
**Auteur** : Claude Code (session 2025-10-10)
**Prochaine session** : D√©marrer par Bug #1 puis Sprint 1 P2
