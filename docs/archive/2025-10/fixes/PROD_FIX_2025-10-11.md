# üîß CORRECTIFS PRODUCTION - 2025-10-11

## üö® Probl√®mes identifi√©s

### CRITIQUE: Database Connection Loss + WebSocket Failures
**Erreur:** `RuntimeError: Database connection is not available.`
**Impact:** WebSocket refuse toutes les connexions ‚Üí Application inutilisable

### D√âGRAD√â: 429 Too Many Requests
**Erreur:** `GET /*.js net::ERR_ABORTED 429`
**Impact:** Modules frontend ne chargent pas ‚Üí Interface partiellement cass√©e

---

## ‚úÖ Fix #1: Retry Logic pour DB (APPLIQU√â)

### Changements effectu√©s dans [src/backend/core/database/manager.py](src/backend/core/database/manager.py)

**Avant:**
```python
async def _ensure_connection(self):
    if not self.is_connected():
        try:
            await self.connect()
        except Exception as e:
            raise RuntimeError("Database connection is not available") from e
```

**Apr√®s:**
```python
async def _ensure_connection(self):
    if not self.is_connected():
        last_error = None
        for attempt in range(self.max_retries):  # 3 tentatives par d√©faut
            try:
                # Force reset
                if self.connection:
                    await self.connection.close()
                    self.connection = None

                await self.connect()
                logger.info(f"Database reconnected (attempt {attempt + 1})")
                break
            except Exception as e:
                last_error = e
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay * (attempt + 1))  # Backoff exponentiel
                else:
                    raise RuntimeError(f"DB unavailable after {self.max_retries} attempts") from last_error
```

**B√©n√©fices:**
- ‚úÖ Reconnexion automatique avec jusqu'√† 3 tentatives
- ‚úÖ Backoff exponentiel (0.5s, 1s, 1.5s)
- ‚úÖ Reset forc√© de la connexion corrompue
- ‚úÖ Logs d√©taill√©s pour monitoring

---

## üîß Fix #2: R√©soudre les 429 Too Many Requests

### Option A: Augmenter containerConcurrency (RECOMMAND√â)

**Commande:**
```bash
gcloud run services update emergence-app \
  --region=europe-west1 \
  --concurrency=80 \
  --max-instances=5
```

**B√©n√©fices:**
- ‚úÖ Solution imm√©diate
- ‚úÖ Permet 80 requ√™tes simultan√©es par instance (au lieu de 40)
- ‚úÖ Max 5 instances pour absorber les pics
- ‚ö†Ô∏è Co√ªt: L√©g√®re augmentation (mais reste dans Free Tier pour usage mod√©r√©)

**Configuration actuelle:**
- containerConcurrency: 40
- CPU: 2000m (2 vCPU)
- Memory: 2Gi

**Configuration propos√©e:**
- containerConcurrency: 80
- CPU: 2000m (inchang√©)
- Memory: 2Gi (inchang√©)
- Max instances: 5

---

### Option B: Bundler les modules frontend (LONG TERME)

Au lieu de charger 15+ fichiers JS s√©par√©s, bundler l'application:

**Avantages:**
- ‚úÖ 1 seule requ√™te au lieu de 15+
- ‚úÖ Chargement plus rapide
- ‚úÖ Moins de pression sur Cloud Run

**Impl√©mentation:**
```bash
# Vite build avec code splitting intelligent
npm run build
# Modifier index.html pour charger les bundles
```

**Effort:** ~2-4h de travail

---

### Option C: CDN pour fichiers statiques (OPTIMAL)

Servir les .js/.css via Cloud CDN ou Cloud Storage:

**Avantages:**
- ‚úÖ Pas de pression sur Cloud Run
- ‚úÖ Latence r√©duite (cache edge)
- ‚úÖ Scaling illimit√©

**Impl√©mentation:**
```bash
# 1. Cr√©er bucket Cloud Storage
gsutil mb -l europe-west1 gs://emergence-static

# 2. Upload des assets
gsutil -m cp -r dist/* gs://emergence-static/

# 3. Rendre public
gsutil iam ch allUsers:objectViewer gs://emergence-static

# 4. Configurer Cloud CDN
gcloud compute backend-buckets create emergence-cdn \
  --gcs-bucket-name=emergence-static \
  --enable-cdn
```

**Effort:** ~4-6h de travail

---

## üöÄ PLAN D'ACTION RECOMMAND√â

### Imm√©diat (< 5 min)

1. **D√©ployer Fix #1 (DB Retry Logic):**
   ```bash
   # Commit et push le code
   git add src/backend/core/database/manager.py
   git commit -m "fix(db): add retry logic for robust reconnection"
   git push

   # Cloud Build d√©ploiera automatiquement
   ```

2. **Appliquer Fix #2A (Augmenter concurrency):**
   ```bash
   gcloud run services update emergence-app \
     --region=europe-west1 \
     --concurrency=80 \
     --max-instances=5
   ```

3. **Monitorer les logs:**
   ```bash
   gcloud logging tail "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app" --format json
   ```

---

### Court terme (24-48h)

1. Tester en prod pendant 24h
2. V√©rifier les m√©triques:
   - Taux d'erreur WebSocket
   - Nombre de 429
   - Latence moyenne

3. Si stable ‚Üí Marquer comme r√©solu

---

### Long terme (1-2 semaines)

1. Impl√©menter Option B (Bundling) ou C (CDN)
2. Ajouter monitoring Prometheus pour:
   - Tentatives de reconnexion DB
   - Taux de succ√®s WebSocket
   - Requ√™tes par seconde

3. Configurer alertes Cloud Monitoring:
   - DB connection failures > 10/min
   - WebSocket error rate > 5%
   - 429 errors > 50/min

---

## üìä M√âTRIQUES DE SUCC√àS

**Avant fix:**
- ‚ùå WebSocket error rate: ~100% (√©chec syst√©matique)
- ‚ùå 429 errors: ~15 par chargement de page
- ‚ùå Application inutilisable

**Apr√®s fix (objectif):**
- ‚úÖ WebSocket error rate: < 1%
- ‚úÖ 429 errors: 0
- ‚úÖ DB reconnection success rate: > 99%
- ‚úÖ Application stable et responsive

---

## üîç V√âRIFICATION POST-D√âPLOIEMENT

```bash
# 1. V√©rifier que le d√©ploiement est termin√©
gcloud run services describe emergence-app --region=europe-west1 --format="value(status.url)"

# 2. Tester une connexion WebSocket
# (ouvrir l'app dans le navigateur et v√©rifier la console)

# 3. V√©rifier les logs de reconnexion DB
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app AND textPayload=~\"Database reconnected\"" --freshness=10m --limit=10

# 4. V√©rifier qu'il n'y a plus de 429
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=emergence-app AND httpRequest.status=429" --freshness=10m --limit=10
```

---

## üìù NOTES

- Le fix #1 (DB retry) est **non-intrusif** et compatible avec le code existant
- Le fix #2A (concurrency) est **r√©versible** en 30 secondes si probl√®me
- Les logs permettront de tracer l'am√©lioration en temps r√©el
- Cold starts Cloud Run peuvent encore causer des latences (~2-3s)

---

**Cr√©√© par:** ProdGuardian + NEO
**Date:** 2025-10-11
**Priorit√©:** P0 (CRITIQUE)
