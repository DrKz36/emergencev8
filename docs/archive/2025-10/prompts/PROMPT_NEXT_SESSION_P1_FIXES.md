# PROMPT SESSION - Corrections Bugs P1-P2 Post-Audit

**Date:** 2025-10-10
**Priorit√©:** P1-P2 (Important - Non bloquant)
**Dur√©e estim√©e:** 4-6 heures
**Bas√© sur:** AUDIT_COMPLET_EMERGENCE_V8_20251010.md (Section 2)

---

## üéØ OBJECTIF DE LA SESSION

Corriger les **7 bugs non-critiques (P1-P2)** identifi√©s dans l'audit complet pour am√©liorer la robustesse et les performances du syst√®me avant la phase de refactoring architectural.

---

## üìã CONTEXTE

### √âtat actuel
‚úÖ **Tous les bugs P0 r√©solus** (2025-10-10) :
- ‚úÖ Bug #1 : Race condition `user_id` dans PreferenceExtractor
- ‚úÖ Bug #2 : Fuite m√©moire cache d'analyse
- ‚úÖ Bug #3 : Absence de locks sur dictionnaires partag√©s

‚ö†Ô∏è **7 bugs P1-P2 restants** n√©cessitant correction :
- **P1** : 3 bugs impactant la fiabilit√©
- **P2** : 4 bugs impactant les performances

### Impact si non corrig√©s
- Risques de suppression globale accidentelle (vector_service)
- Cache pr√©f√©rences obsol√®te pendant 5min
- Requ√™tes N+1 ‚Üí latence √©lev√©e
- M√©tadonn√©es concepts perdues
- Pas de retry sur √©checs LLM
- Risque OOM sur grandes collections ChromaDB

### Documents de r√©f√©rence
1. **AUDIT_COMPLET_EMERGENCE_V8_20251010.md** - Section 2 (Bugs P1-P2)
2. **docs/passation.md** - Derni√®re entr√©e (2025-10-10 10:25)
3. **CODEV_PROTOCOL.md** - Protocole collaboration

---

## üî¥ BUGS P1 (PRIORIT√â HAUTE)

### Bug #4 : Inconsistance gestion `where_filter` vide (P1)
**Temps estim√© :** 30 min

**Fichier :** [src/backend/features/memory/vector_service.py:768-772](src/backend/features/memory/vector_service.py#L768)

**Probl√®me :**
```python
def delete_vectors(self, collection: Collection, where_filter: Dict[str, Any]) -> None:
    if not where_filter:
        logger.warning(f"Suppression annul√©e sur '{collection.name}' (pas de filtre).")
        return
```
Protection contre suppression globale, **MAIS** `where_filter = {"$and": [{"user_id": None}]}` ‚Üí filtre vide accept√© ‚Üí suppression globale possible.

**Solution attendue :**
```python
def _is_filter_empty(self, where_filter: Dict[str, Any]) -> bool:
    """V√©rifie r√©cursivement si un filtre est vide ou sans crit√®res valides."""
    if not where_filter:
        return True

    # V√©rifier op√©rateurs logiques ($and, $or, $not)
    for op in ["$and", "$or"]:
        if op in where_filter:
            values = where_filter[op]
            if isinstance(values, list):
                # Si toutes les sous-conditions sont vides ‚Üí filtre vide
                if all(self._is_filter_empty(v) for v in values):
                    return True

    # V√©rifier si toutes les valeurs sont None
    non_operator_keys = [k for k in where_filter.keys() if not k.startswith("$")]
    if non_operator_keys and all(where_filter[k] is None for k in non_operator_keys):
        return True

    return False

def delete_vectors(self, collection: Collection, where_filter: Dict[str, Any]) -> None:
    if self._is_filter_empty(where_filter):
        logger.error(
            f"[VectorService] Suppression refus√©e sur '{collection.name}': "
            f"filtre vide ou invalide (protection suppression globale)"
        )
        raise ValueError("Cannot delete with empty or invalid filter (global deletion protection)")
```

**Tests √† ajouter :**
```python
# tests/backend/features/test_vector_service_safety.py
async def test_delete_vectors_empty_filter_protection():
    """Test protection contre suppression globale avec filtres vides"""
    # Cas 1: Filtre vide direct
    with pytest.raises(ValueError, match="empty or invalid filter"):
        vector_service.delete_vectors(collection, {})

    # Cas 2: Filtre avec $and vide
    with pytest.raises(ValueError, match="empty or invalid filter"):
        vector_service.delete_vectors(collection, {"$and": []})

    # Cas 3: Filtre avec user_id=None
    with pytest.raises(ValueError, match="empty or invalid filter"):
        vector_service.delete_vectors(collection, {"user_id": None})

    # Cas 4: Filtre valide ‚Üí devrait fonctionner
    vector_service.delete_vectors(collection, {"user_id": "user123"})  # OK
```

---

### Bug #5 : Cache pr√©f√©rences sans invalidation (P1)
**Temps estim√© :** 45 min

**Fichier :** [src/backend/features/chat/memory_ctx.py:132-165](src/backend/features/chat/memory_ctx.py#L132)

**Probl√®me :**
```python
self._prefs_cache: Dict[str, Tuple[str, datetime]] = {}
self._cache_ttl = timedelta(minutes=5)
```
Cache invalid√© **uniquement** par TTL (5min). Si pr√©f√©rence mise √† jour, l'utilisateur voit l'ancienne version pendant 5min.

**Solution attendue :**
```python
# memory_ctx.py - Ajouter m√©thode d'invalidation
def invalidate_preferences_cache(self, user_id: str):
    """Invalide le cache pr√©f√©rences pour un utilisateur donn√©."""
    cache_key = f"prefs:{user_id}"
    if cache_key in self._prefs_cache:
        del self._prefs_cache[cache_key]
        logger.info(f"[MemoryContext] Cache pr√©f√©rences invalid√© pour {user_id}")

# router.py - Invalider apr√®s analyse
@router.post("/api/memory/analyze")
async def analyze_memory(...):
    # ... analyse existante ...

    # Invalider cache pr√©f√©rences apr√®s extraction
    memory_ctx = request.app.state.memory_context
    if memory_ctx and user_id:
        memory_ctx.invalidate_preferences_cache(user_id)

# gardener.py - Invalider apr√®s jardinage
async def tend_garden(...):
    # ... jardinage existant ...

    # Invalider cache apr√®s mise √† jour pr√©f√©rences
    memory_ctx = self.get_memory_context()
    if memory_ctx and user_id:
        memory_ctx.invalidate_preferences_cache(user_id)
```

**Tests √† ajouter :**
```python
# tests/backend/features/test_memory_ctx_cache.py
async def test_preferences_cache_invalidation():
    """Test que le cache est invalid√© apr√®s mise √† jour"""
    user_id = "test_user"

    # 1. Charger pr√©f√©rences (mise en cache)
    prefs1 = await memory_ctx.fetch_active_preferences(user_id, context="test")
    assert prefs1 == "preference v1"

    # 2. Mettre √† jour pr√©f√©rences dans ChromaDB
    update_preferences_in_db(user_id, "preference v2")

    # 3. Sans invalidation ‚Üí cache stale
    prefs2 = await memory_ctx.fetch_active_preferences(user_id, context="test")
    assert prefs2 == "preference v1"  # ‚ùå Ancienne version

    # 4. Avec invalidation ‚Üí cache frais
    memory_ctx.invalidate_preferences_cache(user_id)
    prefs3 = await memory_ctx.fetch_active_preferences(user_id, context="test")
    assert prefs3 == "preference v2"  # ‚úÖ Nouvelle version
```

---

### Bug #6 : Requ√™tes N+1 dans pipeline pr√©f√©rences (P1)
**Temps estim√© :** 60 min

**Fichier :** [src/backend/features/memory/gardener.py:849-865](src/backend/features/memory/gardener.py#L849)

**Probl√®me :**
```python
for record in records:
    existing = await self._get_existing_preference_record(record["id"])
    # ‚ùå Await dans boucle = N requ√™tes s√©quentielles
```

**Impact :** 50 pr√©f√©rences d√©tect√©es ‚Üí 50 requ√™tes ChromaDB s√©quentielles (~35ms/req = 1.75s total).

**Solution attendue :**
```python
async def _get_existing_preferences_batch(
    self, preference_ids: List[str]
) -> Dict[str, Optional[Dict[str, Any]]]:
    """R√©cup√®re plusieurs pr√©f√©rences existantes en une seule requ√™te batch."""
    if not preference_ids:
        return {}

    try:
        result = self.preferences_collection.get(
            ids=preference_ids,
            include=["metadatas", "documents"]
        )

        # Construire dict {id: metadata}
        existing = {}
        if result and result["ids"]:
            for i, pref_id in enumerate(result["ids"]):
                existing[pref_id] = {
                    "metadata": result["metadatas"][i] if result["metadatas"] else {},
                    "document": result["documents"][i] if result["documents"] else ""
                }

        # Remplir les IDs manquants avec None
        for pref_id in preference_ids:
            if pref_id not in existing:
                existing[pref_id] = None

        return existing

    except Exception as e:
        logger.warning(f"[Gardener] Erreur batch fetch pr√©f√©rences: {e}")
        return {pid: None for pid in preference_ids}

async def _store_preference_records(self, records: List[Dict[str, Any]], ...):
    """Version optimis√©e avec batch fetch."""
    if not records:
        return 0

    # Batch fetch toutes les pr√©f√©rences existantes en 1 seule requ√™te
    preference_ids = [r["id"] for r in records]
    existing_prefs = await self._get_existing_preferences_batch(preference_ids)

    saved = 0
    for record in records:
        existing = existing_prefs.get(record["id"])

        # ... logique upsert existante ...

        saved += 1

    return saved
```

**Tests √† ajouter :**
```python
# tests/backend/features/test_gardener_batch.py
async def test_batch_preference_fetch_performance():
    """Test que le batch fetch est plus rapide que N+1"""
    import time

    # Simuler 50 pr√©f√©rences
    records = [{"id": f"pref_{i}", "text": f"Preference {i}"} for i in range(50)]

    # Mesurer temps avec batch fetch (nouvelle impl√©mentation)
    start = time.time()
    await gardener._store_preference_records(records, ...)
    batch_time = time.time() - start

    # Batch fetch devrait √™tre <500ms (vs 1.75s avec N+1)
    assert batch_time < 0.5, f"Batch fetch trop lent: {batch_time}s"
```

---

## üü° BUGS P2 (PRIORIT√â MOYENNE)

### Bug #7 : M√©tadonn√©es perdues dans concepts (P2)
**Temps estim√© :** 30 min

**Fichier :** [src/backend/features/memory/gardener.py:1486-1514](src/backend/features/memory/gardener.py#L1486)

**Probl√®me :**
```python
thread_id = session.get("thread_id")
message_id = session.get("message_id")
# ‚ùå Ces champs ne sont JAMAIS renseign√©s dans les stubs cr√©√©s
```

**Solution :** Renseigner `thread_id` et `message_id` depuis le contexte r√©el de la session.

---

### Bug #8 : Pas de retry sur √©checs LLM (P2)
**Temps estim√© :** 45 min

**Fichier :** [src/backend/features/memory/preference_extractor.py:286-322](src/backend/features/memory/preference_extractor.py#L286)

**Solution :** Ajouter retry (max 2 tentatives) avec fallback sur agent alternatif.

---

### Bug #9 : Pas de timeout sur appels LLM (P2)
**Temps estim√© :** 30 min

**Fichier :** [src/backend/features/memory/analyzer.py:246-322](src/backend/features/memory/analyzer.py#L246)

**Solution :** Wrap avec `asyncio.wait_for(timeout=30)`.

---

### Bug #10 : Chargement complet metadata sans pagination (P2)
**Temps estim√© :** 60 min

**Fichier :** [src/backend/features/memory/gardener.py:1591-1599](src/backend/features/memory/gardener.py#L1591)

**Probl√®me :**
```python
snapshot = self.knowledge_collection.get(include=["metadatas"])
# ‚ùå Charge TOUS les vecteurs de la collection en m√©moire (potentiellement 100k+ items)
```

**Solution :** Impl√©menter pagination ChromaDB avec `offset`/`limit`.

---

## üìù CHECKLIST D'EX√âCUTION

### Pr√©paration (5 min)
- [ ] Lire AUDIT_COMPLET_EMERGENCE_V8_20251010.md Section 2
- [ ] V√©rifier docs/passation.md (derni√®re entr√©e 10:25)
- [ ] S'assurer backend local fonctionne (`curl http://127.0.0.1:8000/api/health`)
- [ ] Activer venv Python

### Phase 1 - Bugs P1 (2h30)
- [ ] **Bug #4** : Validation r√©cursive `where_filter` (30 min)
- [ ] **Bug #5** : Invalidation cache pr√©f√©rences (45 min)
- [ ] **Bug #6** : Batch fetch pr√©f√©rences (60 min)
- [ ] Tests P1 : `pytest tests/backend/features/ -k "safety or cache or batch" -v`

### Phase 2 - Bugs P2 (2h30)
- [ ] **Bug #7** : M√©tadonn√©es concepts (30 min)
- [ ] **Bug #8** : Retry LLM (45 min)
- [ ] **Bug #9** : Timeout LLM (30 min)
- [ ] **Bug #10** : Pagination ChromaDB (60 min)
- [ ] Tests P2 : `pytest tests/backend/features/ -k "metadata or retry or timeout or pagination" -v`

### Validation finale (30 min)
- [ ] Tous tests passent : `pytest tests/backend/features/ -v`
- [ ] Ruff : `ruff check src/backend/features/memory/`
- [ ] Mypy : `mypy src/backend/features/memory/`
- [ ] Build : `npm run build`

### Documentation (15 min)
- [ ] Mettre √† jour `docs/passation.md` avec nouvelle entr√©e :
  - Agent: Claude Code
  - Date: 2025-10-10 [HH:MM]
  - Fichiers modifi√©s (liste compl√®te)
  - Tests : X/X PASSED
  - Statut : ‚úÖ Bugs P1-P2 r√©solus

---

## üéØ CRIT√àRES DE SUCC√àS

### R√©sultats attendus
‚úÖ **Bug #4** : Protection suppression globale avec validation r√©cursive
‚úÖ **Bug #5** : Cache pr√©f√©rences invalid√© apr√®s mise √† jour
‚úÖ **Bug #6** : Batch fetch pr√©f√©rences (<500ms vs 1.75s)
‚úÖ **Bug #7** : M√©tadonn√©es concepts renseign√©es
‚úÖ **Bug #8** : Retry LLM (max 2 tentatives)
‚úÖ **Bug #9** : Timeout LLM (30s)
‚úÖ **Bug #10** : Pagination ChromaDB impl√©ment√©e

### Livrables
1. **Code modifi√©** : 6+ fichiers (vector_service, memory_ctx, gardener, preference_extractor, analyzer)
2. **Tests ajout√©s** : 10+ tests (safety, cache, batch, retry, pagination)
3. **Documentation** : Entr√©e `docs/passation.md` compl√®te

---

## ‚ö†Ô∏è POINTS D'ATTENTION

### Priorit√© des bugs
1. **P1 d'abord** : Bugs #4, #5, #6 (risques fiabilit√©)
2. **P2 ensuite** : Bugs #7, #8, #9, #10 (optimisations)

### Pi√®ges √† √©viter
‚ùå **NE PAS** tester manuellement les suppressions globales (risque perte donn√©es)
‚ùå **NE PAS** oublier d'invalider cache dans tous les points d'entr√©e (router + gardener)
‚ùå **NE PAS** impl√©menter batch fetch sans tests de performance

### Bonnes pratiques
‚úÖ Tests unitaires pour chaque bug corrig√©
‚úÖ Logger toutes les protections (suppressions refus√©es, cache invalid√©)
‚úÖ Mesurer gains performance (avant/apr√®s batch fetch)

---

## üìö RESSOURCES

### Fichiers √† consulter
1. **AUDIT_COMPLET_EMERGENCE_V8_20251010.md** (Section 2)
2. **src/backend/features/memory/vector_service.py**
3. **src/backend/features/chat/memory_ctx.py**
4. **src/backend/features/memory/gardener.py**
5. **src/backend/features/memory/preference_extractor.py**
6. **src/backend/features/memory/analyzer.py**

### Tests existants
- `tests/backend/features/test_memory_enhancements.py`
- `tests/backend/features/test_memory_cache_eviction.py`
- `tests/backend/features/test_memory_concurrency.py`

---

## üöÄ APR√àS CETTE SESSION

### Prochaines priorit√©s (Phase 1 - Fin)
1. **Nettoyage projet** : ~13 Mo fichiers obsol√®tes (voir `CLEANUP_PLAN_20251010.md`)
2. **Mise √† jour documentation** : Corriger incoh√©rences Section 5 audit
3. **D√©ploiement production** : D√©ployer tous fixes P0/P1/P2 sur Cloud Run

### Session suivante sugg√©r√©e
**PROMPT_NEXT_SESSION_CLEANUP.md** (nettoyage + documentation)

---

**Prompt g√©n√©r√© le:** 2025-10-10 10:30
**Bas√© sur:** AUDIT_COMPLET_EMERGENCE_V8_20251010.md (Section 2)
**Priorit√©:** P1-P2 (Important)
**Dur√©e estim√©e:** 4-6 heures
**Agent recommand√©:** Claude Code (expertise Python/async/ChromaDB)

---

## üìä √âTAT ACTUEL DU PROJET

### Bugs Critiques (P0)
- ‚úÖ Bug #1 : PreferenceExtractor user_id (R√âSOLU 2025-10-10 09:40)
- ‚úÖ Bug #2 : Fuite m√©moire cache (R√âSOLU 2025-10-10 10:25)
- ‚úÖ Bug #3 : Race conditions locks (R√âSOLU 2025-10-10 10:25)

### Bugs Non-Critiques
- ‚ö†Ô∏è Bug #4-10 : 7 bugs P1-P2 √† corriger (CETTE SESSION)

### Tests Actuels
- 232 tests pytest identifi√©s
- 16 tests P0 ajout√©s aujourd'hui (√©viction + concurrence)
- Couverture estim√©e : ~60%

**Objectif post-session :** 70% couverture, 0 bugs P1 restants
