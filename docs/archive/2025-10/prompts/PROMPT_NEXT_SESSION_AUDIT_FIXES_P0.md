# PROMPT SESSION - Corrections Bugs Critiques Post-Audit

**Date:** 2025-10-10
**Priorit√©:** P0 (Critique - Urgent)
**Dur√©e estim√©e:** 2-3 heures
**Bas√© sur:** AUDIT_COMPLET_EMERGENCE_V8_20251010.md

---

## üéØ OBJECTIF DE LA SESSION

Corriger les **2 bugs critiques P0 restants** identifi√©s dans l'audit complet, qui pr√©sentent des risques de production (fuite m√©moire, race conditions).

---

## üìã CONTEXTE

### √âtat actuel
‚úÖ **Bug #1 R√âSOLU** : Race condition `user_id` dans PreferenceExtractor (d√©ploy√© le 2025-10-10)

‚ö†Ô∏è **Bug #2 NON R√âSOLU** : Fuite m√©moire dans le cache d'analyse
‚ö†Ô∏è **Bug #3 NON R√âSOLU** : Absence de locks sur dictionnaires partag√©s

### Impact si non corrig√©s
- **Bug #2** : Consommation m√©moire croissante ‚Üí OOM (Out of Memory) en production
- **Bug #3** : Race conditions ‚Üí corruption donn√©es, comportement non d√©terministe

### Documents de r√©f√©rence
1. **AUDIT_COMPLET_EMERGENCE_V8_20251010.md** - Rapport complet (Section 1: Bugs Critiques)
2. **docs/passation.md** - Journal inter-agents (derni√®re entr√©e: 2025-10-10 09:40)
3. **CODEV_PROTOCOL.md** - Protocole collaboration

---

## üî¥ BUG #2 : FUITE M√âMOIRE DANS CACHE D'ANALYSE

### Localisation
**Fichier:** [src/backend/features/memory/analyzer.py:70, 358-362](src/backend/features/memory/analyzer.py#L70)

### Code probl√©matique

```python
# Ligne 70
_ANALYSIS_CACHE: Dict[str, tuple[Dict[str, Any], datetime]] = {}

# Lignes 358-362
if len(_ANALYSIS_CACHE) > 100:
    oldest_key = min(_ANALYSIS_CACHE.keys(), key=lambda k: _ANALYSIS_CACHE[k][1])
    del _ANALYSIS_CACHE[oldest_key]  # ‚ùå Supprime SEULEMENT 1 √©l√©ment
```

### Probl√®me
Si burst de 200+ consolidations ‚Üí le cache grandit ind√©finiment car on ne supprime qu'1 √©l√©ment alors que 100+ entr√©es existent d√©j√†.

### Solution attendue

```python
# Ligne 70 - Ajouter constantes
_ANALYSIS_CACHE: Dict[str, tuple[Dict[str, Any], datetime]] = {}
MAX_CACHE_SIZE = 100
EVICTION_THRESHOLD = 80  # √âviction agressive quand >80 entr√©es

# Lignes 358-370 - Remplacer par √©viction agressive
if len(_ANALYSIS_CACHE) > EVICTION_THRESHOLD:
    # Trier par timestamp et garder les 50 plus r√©cents
    sorted_keys = sorted(
        _ANALYSIS_CACHE.keys(),
        key=lambda k: _ANALYSIS_CACHE[k][1],
        reverse=True
    )
    # Supprimer les anciennes entr√©es (garder top 50)
    for key in sorted_keys[50:]:
        del _ANALYSIS_CACHE[key]

    logger.info(
        f"[MemoryAnalyzer] Cache √©viction: {len(sorted_keys) - 50} entr√©es "
        f"supprim√©es (cache size: {len(_ANALYSIS_CACHE)})"
    )
```

### Tests √† ajouter

```python
# tests/backend/features/test_memory_cache_eviction.py
import pytest
from backend.features.memory.analyzer import MemoryAnalyzer, _ANALYSIS_CACHE
from datetime import datetime, timedelta

@pytest.fixture
def analyzer(mock_db_manager, mock_chat_service):
    return MemoryAnalyzer(mock_db_manager, mock_chat_service)

async def test_cache_eviction_aggressive():
    """Test que l'√©viction est agressive (supprime 50+ entr√©es)"""
    # Simuler 100 entr√©es
    for i in range(100):
        _ANALYSIS_CACHE[f"session_{i}"] = (
            {"summary": f"test_{i}"},
            datetime.now() - timedelta(minutes=i)
        )

    assert len(_ANALYSIS_CACHE) == 100

    # Ajouter 1 entr√©e suppl√©mentaire pour d√©clencher √©viction
    _ANALYSIS_CACHE["session_100"] = ({"summary": "test_100"}, datetime.now())

    # Simuler √©viction (appeler m√©thode priv√©e ou d√©clencher via consolidation)
    # L'√©viction devrait ramener cache √† ~50 entr√©es

    # V√©rifier que cache r√©duit √† ~50 (pas juste -1)
    assert len(_ANALYSIS_CACHE) <= 55  # Tol√©rance ¬±5

async def test_cache_keeps_most_recent():
    """Test que l'√©viction garde les plus r√©cents"""
    # Simuler 100 entr√©es avec timestamps √©chelonn√©s
    old_keys = []
    recent_keys = []

    for i in range(80):
        key = f"old_{i}"
        _ANALYSIS_CACHE[key] = ({"summary": "old"}, datetime.now() - timedelta(hours=i))
        old_keys.append(key)

    for i in range(30):
        key = f"recent_{i}"
        _ANALYSIS_CACHE[key] = ({"summary": "recent"}, datetime.now())
        recent_keys.append(key)

    # D√©clencher √©viction
    # ...

    # V√©rifier que les r√©cents sont gard√©s
    for key in recent_keys[:20]:  # Au moins 20 r√©cents gard√©s
        assert key in _ANALYSIS_CACHE

    # V√©rifier que les anciens sont supprim√©s
    for key in old_keys[50:]:  # Anciens >50 supprim√©s
        assert key not in _ANALYSIS_CACHE
```

### Validation

```bash
# Tests
pytest tests/backend/features/test_memory_cache_eviction.py -v

# Linting
ruff check src/backend/features/memory/analyzer.py

# Type checking
mypy src/backend/features/memory/analyzer.py
```

---

## üî¥ BUG #3 : ABSENCE DE LOCKS SUR DICTIONNAIRES PARTAG√âS

### Localisations multiples

1. [src/backend/features/memory/analyzer.py:70](src/backend/features/memory/analyzer.py#L70) ‚Üí `_ANALYSIS_CACHE`
2. [src/backend/features/memory/incremental_consolidation.py:29](src/backend/features/memory/incremental_consolidation.py#L29) ‚Üí `self.message_counters`
3. [src/backend/features/memory/proactive_hints.py:66-67](src/backend/features/memory/proactive_hints.py#L66) ‚Üí `self._concept_counters`
4. [src/backend/features/memory/intent_tracker.py:65](src/backend/features/memory/intent_tracker.py#L65) ‚Üí `self.reminder_counts`

### Probl√®me
Dictionnaires partag√©s modifi√©s sans lock ‚Üí **race conditions** si 2+ analyses concurrentes ‚Üí corruption donn√©es.

### Solution attendue

#### 1. MemoryAnalyzer (analyzer.py)

```python
import asyncio
from typing import Dict, Any, Tuple
from datetime import datetime

class MemoryAnalyzer:
    def __init__(self, db_manager, ...):
        self._cache_lock = asyncio.Lock()
        self._cache: Dict[str, Tuple[Dict[str, Any], datetime]] = {}
        # ... reste init

    async def _get_from_cache(self, key: str) -> Optional[Tuple[Dict[str, Any], datetime]]:
        """R√©cup√®re entr√©e du cache de mani√®re thread-safe"""
        async with self._cache_lock:
            return self._cache.get(key)

    async def _put_in_cache(self, key: str, value: Dict[str, Any], timestamp: datetime):
        """Ajoute entr√©e au cache de mani√®re thread-safe"""
        async with self._cache_lock:
            self._cache[key] = (value, timestamp)

            # √âviction agressive (ici, sous lock)
            if len(self._cache) > EVICTION_THRESHOLD:
                sorted_keys = sorted(
                    self._cache.keys(),
                    key=lambda k: self._cache[k][1],
                    reverse=True
                )
                for key in sorted_keys[50:]:
                    del self._cache[key]

                logger.info(f"[Cache] √âviction: {len(sorted_keys) - 50} entr√©es supprim√©es")

    async def _remove_from_cache(self, key: str):
        """Supprime entr√©e du cache de mani√®re thread-safe"""
        async with self._cache_lock:
            self._cache.pop(key, None)
```

#### 2. IncrementalConsolidator (incremental_consolidation.py)

```python
import asyncio
from typing import Dict

class IncrementalConsolidator:
    def __init__(self, ...):
        self._counter_lock = asyncio.Lock()
        self.message_counters: Dict[str, int] = {}

    async def increment_counter(self, session_id: str) -> int:
        """Incr√©mente compteur de mani√®re thread-safe"""
        async with self._counter_lock:
            self.message_counters[session_id] = self.message_counters.get(session_id, 0) + 1
            return self.message_counters[session_id]

    async def get_counter(self, session_id: str) -> int:
        """R√©cup√®re compteur de mani√®re thread-safe"""
        async with self._counter_lock:
            return self.message_counters.get(session_id, 0)

    async def reset_counter(self, session_id: str):
        """Remet compteur √† z√©ro de mani√®re thread-safe"""
        async with self._counter_lock:
            self.message_counters[session_id] = 0
```

#### 3. ProactiveHintEngine (proactive_hints.py)

```python
import asyncio

class ConceptTracker:
    def __init__(self):
        self._counter_lock = asyncio.Lock()
        self._concept_counters: Dict[str, int] = {}

    async def increment(self, concept_id: str) -> int:
        async with self._counter_lock:
            self._concept_counters[concept_id] = self._concept_counters.get(concept_id, 0) + 1
            return self._concept_counters[concept_id]

    async def get_count(self, concept_id: str) -> int:
        async with self._counter_lock:
            return self._concept_counters.get(concept_id, 0)
```

#### 4. IntentTracker (intent_tracker.py)

```python
import asyncio

class IntentTracker:
    def __init__(self, ...):
        self._reminder_lock = asyncio.Lock()
        self.reminder_counts: Dict[str, int] = {}

    async def increment_reminder(self, intent_id: str) -> int:
        async with self._reminder_lock:
            self.reminder_counts[intent_id] = self.reminder_counts.get(intent_id, 0) + 1
            return self.reminder_counts[intent_id]

    async def get_reminder_count(self, intent_id: str) -> int:
        async with self._reminder_lock:
            return self.reminder_counts.get(intent_id, 0)
```

### Tests √† ajouter

```python
# tests/backend/features/test_memory_concurrency.py
import pytest
import asyncio
from backend.features.memory.analyzer import MemoryAnalyzer

async def test_cache_concurrent_access():
    """Test que le cache g√®re correctement les acc√®s concurrents"""
    analyzer = MemoryAnalyzer(...)

    async def write_cache(i: int):
        await analyzer._put_in_cache(f"key_{i}", {"data": i}, datetime.now())

    # Lancer 100 √©critures concurrentes
    tasks = [write_cache(i) for i in range(100)]
    await asyncio.gather(*tasks)

    # V√©rifier aucune corruption
    cache_size = len(analyzer._cache)
    assert cache_size > 0  # Au moins quelques entr√©es gard√©es
    assert cache_size <= 100  # Pas de d√©passement

async def test_counter_concurrent_increments():
    """Test que les compteurs g√®rent correctement les incr√©ments concurrents"""
    consolidator = IncrementalConsolidator(...)
    session_id = "test_session"

    async def increment():
        await consolidator.increment_counter(session_id)

    # Lancer 50 incr√©ments concurrents
    tasks = [increment() for _ in range(50)]
    await asyncio.gather(*tasks)

    # V√©rifier compteur correct (pas de race condition)
    count = await consolidator.get_counter(session_id)
    assert count == 50  # Tous les incr√©ments compt√©s
```

### Validation

```bash
# Tests concurrence
pytest tests/backend/features/test_memory_concurrency.py -v

# Tests existants (non-r√©gression)
pytest tests/backend/features/test_memory_enhancements.py -v

# Type checking
mypy src/backend/features/memory/
```

---

## üìù CHECKLIST D'EX√âCUTION

### Pr√©paration (5 min)

- [ ] Lire AUDIT_COMPLET_EMERGENCE_V8_20251010.md Section 1
- [ ] V√©rifier docs/passation.md (derni√®re entr√©e)
- [ ] S'assurer backend local fonctionne (`curl http://127.0.0.1:8000/api/health`)
- [ ] Activer venv Python (`.venv/Scripts/Activate.ps1` ou `source .venv/bin/activate`)

### Bug #2 - Fuite m√©moire cache (45 min)

- [ ] Lire code actuel `src/backend/features/memory/analyzer.py:70, 358-362`
- [ ] Impl√©menter constantes `MAX_CACHE_SIZE`, `EVICTION_THRESHOLD`
- [ ] Remplacer √©viction simple par √©viction agressive (garder top 50)
- [ ] Ajouter log `[MemoryAnalyzer] Cache √©viction: X entr√©es supprim√©es`
- [ ] Cr√©er tests `tests/backend/features/test_memory_cache_eviction.py`
- [ ] Ex√©cuter tests : `pytest tests/backend/features/test_memory_cache_eviction.py -v`
- [ ] V√©rifier ruff : `ruff check src/backend/features/memory/analyzer.py`
- [ ] V√©rifier mypy : `mypy src/backend/features/memory/analyzer.py`

### Bug #3 - Locks dictionnaires (90 min)

**3.1 MemoryAnalyzer (20 min)**
- [ ] Ajouter `self._cache_lock = asyncio.Lock()`
- [ ] Cr√©er m√©thodes `_get_from_cache()`, `_put_in_cache()`, `_remove_from_cache()`
- [ ] Remplacer tous acc√®s directs `_ANALYSIS_CACHE` par m√©thodes lock√©es
- [ ] Tester

**3.2 IncrementalConsolidator (20 min)**
- [ ] Ajouter `self._counter_lock = asyncio.Lock()`
- [ ] Cr√©er m√©thodes `increment_counter()`, `get_counter()`, `reset_counter()`
- [ ] Remplacer acc√®s directs `self.message_counters` par m√©thodes lock√©es
- [ ] Tester

**3.3 ProactiveHintEngine (20 min)**
- [ ] Ajouter `self._counter_lock = asyncio.Lock()` dans `ConceptTracker`
- [ ] Cr√©er m√©thodes `increment()`, `get_count()`
- [ ] Remplacer acc√®s directs `self._concept_counters` par m√©thodes lock√©es
- [ ] Tester

**3.4 IntentTracker (20 min)**
- [ ] Ajouter `self._reminder_lock = asyncio.Lock()`
- [ ] Cr√©er m√©thodes `increment_reminder()`, `get_reminder_count()`
- [ ] Remplacer acc√®s directs `self.reminder_counts` par m√©thodes lock√©es
- [ ] Tester

**3.5 Tests concurrence (10 min)**
- [ ] Cr√©er `tests/backend/features/test_memory_concurrency.py`
- [ ] Test `test_cache_concurrent_access()`
- [ ] Test `test_counter_concurrent_increments()`
- [ ] Ex√©cuter : `pytest tests/backend/features/test_memory_concurrency.py -v`

### Validation finale (15 min)

- [ ] Tous tests passent : `pytest tests/backend/features/ -v`
- [ ] Tests m√©moire : `pytest tests/backend/features/ -k memory -v`
- [ ] Ruff : `ruff check src/backend/features/memory/`
- [ ] Mypy : `mypy src/backend/features/memory/`
- [ ] Build : `npm run build`
- [ ] Backend d√©marre : `python -m uvicorn --app-dir src backend.main:app`

### Documentation (10 min)

- [ ] Mettre √† jour `docs/passation.md` avec nouvelle entr√©e :
  - Agent: Claude Code
  - Date: 2025-10-10 [HH:MM]
  - Fichiers modifi√©s (liste compl√®te)
  - Tests : X/X PASSED
  - Statut : ‚úÖ Bugs P0 #2 et #3 r√©solus

---

## üéØ CRIT√àRES DE SUCC√àS

### R√©sultats attendus

‚úÖ **Bug #2** : √âviction agressive impl√©ment√©e (garde top 50 au lieu de supprimer 1)
‚úÖ **Bug #3** : Locks `asyncio.Lock()` sur tous dictionnaires partag√©s (4 fichiers)
‚úÖ **Tests** : Nouveaux tests concurrence passent (100%)
‚úÖ **Non-r√©gression** : Tests existants m√©moire passent (100%)
‚úÖ **Qualit√©** : Ruff + Mypy sans erreur

### Livrables

1. **Code modifi√©** :
   - `src/backend/features/memory/analyzer.py` (√©viction + locks)
   - `src/backend/features/memory/incremental_consolidation.py` (locks)
   - `src/backend/features/memory/proactive_hints.py` (locks)
   - `src/backend/features/memory/intent_tracker.py` (locks)

2. **Tests ajout√©s** :
   - `tests/backend/features/test_memory_cache_eviction.py` (2+ tests)
   - `tests/backend/features/test_memory_concurrency.py` (2+ tests)

3. **Documentation** :
   - Entr√©e `docs/passation.md` (date, fichiers, tests, statut)

---

## ‚ö†Ô∏è POINTS D'ATTENTION

### Pi√®ges √† √©viter

‚ùå **NE PAS** utiliser `threading.Lock()` ‚Üí utiliser `asyncio.Lock()` (code async)
‚ùå **NE PAS** oublier les locks dans les m√©thodes priv√©es (ex: `_evict_cache()`)
‚ùå **NE PAS** deadlock ‚Üí toujours lib√©rer lock (`async with` garantit release)
‚ùå **NE PAS** acc√©der dictionnaires partag√©s en dehors des m√©thodes lock√©es

### Bonnes pratiques

‚úÖ Toujours wrapper acc√®s dictionnaire dans `async with self._lock:`
‚úÖ Garder sections critiques (sous lock) courtes
‚úÖ Logger √©victions cache pour observabilit√©
‚úÖ Tester concurrence avec `asyncio.gather()` (simule charge)

---

## üìö RESSOURCES

### Fichiers √† consulter

1. **AUDIT_COMPLET_EMERGENCE_V8_20251010.md** (Section 1, 2, 7)
2. **src/backend/features/memory/analyzer.py**
3. **src/backend/features/memory/incremental_consolidation.py**
4. **src/backend/features/memory/proactive_hints.py**
5. **src/backend/features/memory/intent_tracker.py**
6. **docs/passation.md**

### Documentation Python

- [asyncio.Lock](https://docs.python.org/3/library/asyncio-sync.html#asyncio.Lock)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [mypy async](https://mypy.readthedocs.io/en/stable/cheat_sheet_py3.html#coroutines-and-asyncio)

---

## üöÄ APR√àS CETTE SESSION

### Prochaines priorit√©s (Phase 1 - Suite)

1. **Bugs P1-P2** (7 bugs non-critiques identifi√©s dans audit)
2. **Nettoyage projet** (ex√©cuter `CLEANUP_PLAN_20251010.md`)
3. **Mise √† jour documentation** (corriger incoh√©rences Section 5 audit)

### Session suivante sugg√©r√©e

**PROMPT_NEXT_SESSION_AUDIT_FIXES_P1.md** (bugs non-critiques + nettoyage)

---

**Prompt g√©n√©r√© le:** 2025-10-10
**Bas√© sur:** AUDIT_COMPLET_EMERGENCE_V8_20251010.md
**Priorit√©:** P0 - Critique
**Dur√©e estim√©e:** 2-3 heures
**Agent recommand√©:** Claude Code (expertise Python/async)
