# üìã P1.5 Implementation Summary - √âMERGENCE V8

## ‚úÖ Impl√©mentations Compl√©t√©es

### 1. **Lifespan FastAPI Unique**
**Fichier**: [`src/backend/main.py`](../src/backend/main.py)

- ‚úÖ Conversion `@app.on_event("startup")` ‚Üí `@asynccontextmanager async def lifespan()`
- ‚úÖ Initialisation centralis√©e :
  - DatabaseManager (connect/disconnect)
  - MemoryTaskQueue (start/stop)
  - AutoSyncService (start/stop)
  - VoiceService httpx client (aclose)
  - DI Container (unwire)
- ‚úÖ Logs structur√©s avec emojis (üöÄ startup, üîª shutdown, ‚úÖ success)
- ‚úÖ Gestion d'erreurs robuste (continue sur √©chec partiel)

**Usage**:
```python
app = FastAPI(
    title="√âmergence API",
    version="8.0",
    lifespan=lifespan  # ‚Üê Context manager moderne
)
```

---

### 2. **Health Checks Avanc√©s (Kubernetes-ready)**
**Fichiers**: [`src/backend/main.py`](../src/backend/main.py) et [`src/backend/features/monitoring/router.py`](../src/backend/features/monitoring/router.py)

#### **Liveness Probe** (`/healthz`)
V√©rifie que le processus est vivant et peut traiter des requ√™tes.

**Retour**:
```json
{
  "ok": true
}
```

#### **Readiness Probe** (`/ready`)
V√©rifie tous les services critiques :
- **Database** (SQLite/PostgreSQL) : `SELECT 1` ping
- **VectorService** (Chroma/Qdrant) : list collections
- **LLM Providers** (OpenAI, Anthropic, Google) : check clients configur√©s

**Retour (exemple success)**:
```json
{
  "ok": true,
  "db": "up",
  "vector": "up"
}
```

**Retour (exemple error, status 503)**:
```json
{
  "ok": false,
  "error": "Database connection failed"
}
```

**Note**: Pour des health checks d√©taill√©s avec m√©triques syst√®me compl√®tes, utiliser `/api/monitoring/health/detailed` ou `/api/monitoring/system/info`.

**Int√©gration Kubernetes/Cloud Run**:
```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 30

readinessProbe:
  httpGet:
    path: /ready
    port: 8000
  initialDelaySeconds: 15
  periodSeconds: 10
```

---

### 3. **RAG Hybride (BM25 + Vectoriel)**
**Fichier**: [`src/backend/features/memory/hybrid_retriever.py`](../src/backend/features/memory/hybrid_retriever.py)

#### **Architecture**
- **BM25Scorer** : Ranking lexical (Okapi BM25)
  - Tokenization simple (lowercase + regex `\b\w+\b`)
  - IDF : `log((N - n(t) + 0.5) / (n(t) + 0.5) + 1)`
  - Score : `Œ£ IDF(qi) ¬∑ (f(qi,D) ¬∑ (k1+1)) / (f(qi,D) + k1 ¬∑ (1-b + b¬∑|D|/avgdl))`

- **HybridRetriever** : Fusion BM25 + Vector
  - **alpha** : poids vectoriel (0.0 = full BM25, 1.0 = full vector)
  - **score_threshold** : seuil minimum pour retourner un r√©sultat
  - **top_k** : nombre de r√©sultats finaux
  - Fusion : `hybrid_score = (1 - alpha) * bm25_score + alpha * vector_score`
  - Normalisation : scores dans [0, 1]

#### **Param√®tres Configurables**
| Param√®tre | D√©faut | Description |
|-----------|--------|-------------|
| `alpha` | 0.5 | Poids scoring vectoriel (0=lexical, 1=s√©mantique) |
| `score_threshold` | 0.0 | Seuil minimum de pertinence |
| `top_k` | 5 | Nombre de r√©sultats |
| `bm25_k1` | 1.5 | Saturation term frequency BM25 |
| `bm25_b` | 0.75 | Normalisation longueur document BM25 |

#### **Usage dans VectorService**
**M√©thode ajout√©e**: `VectorService.hybrid_query()`

```python
# Exemple d'utilisation
hybrid_results = vector_service.hybrid_query(
    collection=knowledge_col,
    query_text="Comment configurer le RAG ?",
    n_results=5,
    where_filter={"session_id": session_id},
    alpha=0.5,           # 50% BM25, 50% vector
    score_threshold=0.3, # Minimum 30% de pertinence
)

# R√©sultat
[
    {
        "text": "Le RAG combine recherche lexicale et s√©mantique...",
        "score": 0.87,       # Score hybride
        "bm25_score": 0.65,  # Score BM25 seul
        "vector_score": 0.92, # Score vectoriel seul
        "metadata": {...}
    },
    ...
]
```

**Fallback automatique** :
- Si `hybrid_retriever.py` non disponible ‚Üí fallback sur `query()` classique
- Si erreur BM25 ‚Üí fallback sur recherche vectorielle pure

---

### 4. **Frontend : Flag RAG Strict** (Recommandations)

#### **√âtat √† Ajouter** (dans `ChatModule.initializeState()`)
```javascript
this.state.set('chat', {
  // ... existant
  ragEnabled: false,
  ragStrictMode: false,  // ‚Üê NOUVEAU : mode RAG strict
  ragMinScore: 0.3,      // ‚Üê NOUVEAU : seuil minimum
  ragUseHybrid: true,    // ‚Üê NOUVEAU : activer BM25+vector
  ragAlpha: 0.5,         // ‚Üê NOUVEAU : poids vectoriel
});
```

#### **UI Toggle √† Ajouter** (dans `chat-ui.js`)
```html
<div class="rag-controls">
  <label class="toggle">
    <input type="checkbox" id="rag-strict-toggle" />
    <span>RAG Strict</span>
  </label>
  <div class="rag-settings" id="rag-settings-panel">
    <label>
      Seuil : <input type="range" min="0" max="100" value="30" id="rag-threshold" />
      <span id="rag-threshold-value">0.30</span>
    </label>
    <label class="toggle">
      <input type="checkbox" id="rag-hybrid-toggle" checked />
      <span>Scoring hybride (BM25+Vector)</span>
    </label>
  </div>
</div>
```

#### **Logique Backend √† Adapter** (dans `ChatService`)
```python
# Dans _build_memory_context() ou query RAG
if use_rag:
    strict_mode = request_payload.get("rag_strict_mode", False)
    min_score = request_payload.get("rag_min_score", 0.0)
    use_hybrid = request_payload.get("rag_use_hybrid", False)

    if use_hybrid:
        results = self.vector_service.hybrid_query(
            collection=doc_collection,
            query_text=query,
            n_results=top_k,
            where_filter=where,
            alpha=request_payload.get("rag_alpha", 0.5),
            score_threshold=min_score if strict_mode else 0.0,
        )
    else:
        results = self.vector_service.query(...)

    # Mode strict : filtrer par score
    if strict_mode and min_score > 0:
        results = [r for r in results if r.get("score", 0) >= min_score]

    # Si aucun r√©sultat en mode strict ‚Üí message explicite
    if strict_mode and not results:
        return "‚ö†Ô∏è RAG strict : Aucune source fiable trouv√©e (seuil {min_score})."
```

#### **Affichage des Scores** (dans message meta)
```javascript
// Dans handleStreamEnd(), ajouter scores √† meta
if (payload.meta?.sources) {
    payload.meta.sources.forEach(source => {
        // Ajouter affichage score dans l'UI
        const scoreLabel = source.score
            ? `${(source.score * 100).toFixed(0)}%`
            : '';
        // Badge avec score + source
    });
}
```

---

## üß™ Tests de Validation

### **1. D√©marrage avec Lifespan**
```bash
cd c:\dev\emergenceV8
python src/backend/main.py
# Logs attendus :
# üöÄ Lifespan: D√©marrage backend √âmergence‚Ä¶
# ‚úÖ Lifespan: Backend pr√™t
```

### **2. Health Checks**
```bash
# Liveness (simple)
curl http://localhost:8000/healthz
# {"ok":true}

# Readiness (complet)
curl http://localhost:8000/ready
# {"ok":true,"db":"up","vector":"up"}
```

### **3. RAG Hybride**
```python
# Test unitaire (√† cr√©er)
from backend.features.memory.hybrid_retriever import HybridRetriever

corpus = [
    "Le RAG combine recherche lexicale et s√©mantique",
    "BM25 est un algorithme de ranking",
    "Les embeddings capturent la s√©mantique"
]

retriever = HybridRetriever(alpha=0.5, top_k=2)
results = retriever.retrieve("comment fonctionne le RAG", corpus, [])

assert len(results) <= 2
assert all("score" in r for r in results)
assert all("bm25_score" in r for r in results)
```

### **4. Frontend RAG Strict**
1. Activer toggle "RAG Strict" dans l'UI
2. Ajuster seuil √† 0.5 (50%)
3. Poser question : "Quelle est la capitale de la France ?"
4. Si aucun document pertinent ‚Üí message "‚ö†Ô∏è Aucune source fiable"
5. V√©rifier affichage des scores dans les sources retenues

---

## üìä M√©triques & Monitoring

### **Prometheus Metrics** (existant, √† compl√©ter)
```python
# Dans /api/metrics
{
  "rag_queries_total": 1234,
  "rag_queries_hybrid": 567,
  "rag_queries_strict_filtered": 89,
  "rag_avg_score": 0.67,
  "health_checks_total": 456,
  "health_checks_failed": 12
}
```

---

## üöÄ D√©ploiement Production

### **Variables d'Environnement**
```bash
# RAG Hybride
export RAG_DEFAULT_ALPHA=0.5        # Poids vectoriel par d√©faut
export RAG_DEFAULT_THRESHOLD=0.0    # Seuil strict d√©sactiv√© par d√©faut
export RAG_BM25_K1=1.5              # Param√®tre BM25
export RAG_BM25_B=0.75              # Normalisation longueur BM25

# Health Checks
export HEALTH_CHECK_TIMEOUT_MS=5000 # Timeout checks
```

### **Docker Health Checks**
```dockerfile
HEALTHCHECK --interval=30s --timeout=5s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/healthz || exit 1
```

---

## üìù TODO Restants (Optionnels)

1. ‚¨ú Tests E2E pour RAG hybride
2. ‚¨ú Dashboard Grafana pour m√©triques health checks
3. ‚¨ú Impl√©mentation RRF (Reciprocal Rank Fusion) comme alternative √† weighted average
4. ‚¨ú Cache Redis pour r√©sultats BM25 (performance)
5. ‚¨ú A/B testing alpha optimal (ML exp√©rience)

---

## üìö R√©f√©rences

- **BM25**: [Wikipedia - Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)
- **FastAPI Lifespan**: [Docs - Lifespan Events](https://fastapi.tiangolo.com/advanced/events/)
- **Kubernetes Probes**: [Docs - Liveness/Readiness](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)

---

**Version**: P1.5 - √âmergence V8
**Date**: 2025-10-11
**Auteur**: Claude (Anthropic)
