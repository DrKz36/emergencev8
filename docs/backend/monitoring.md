# Monitoring Feature - Advanced Health Checks

**Module**: `src/backend/features/monitoring/router.py`
**Version**: P1.6 (√âmergence V8)
**Derni√®re mise √† jour**: 2025-11-30

## Vue d'ensemble

Le module Monitoring fournit des endpoints de healthcheck avanc√©s, compatibles Kubernetes, et des dashboards admin pour l'observabilit√© de l'application √âMERGENCE.

## Architecture

Le syst√®me de monitoring repose sur 3 couches:

1. **Health Checks**: Probes K8s (liveness, readiness) + healthchecks d√©taill√©s
2. **M√©triques Application**: Statistiques endpoints, erreurs, latences
3. **Monitoring S√©curit√©/Performance**: D√©tection patterns suspects, slow queries, temps IA

---

## Authentification & S√©curit√© (mise √† jour 2025-11-30)

- Tous les endpoints `/api/monitoring/**` (metrics, s√©curit√©, performance, `/api/system/info`, etc.) exigent d√©sormais un **JWT admin** dans l‚Äôen-t√™te `Authorization: Bearer <token>`.
- La d√©pendance FastAPI `verify_admin()` :
  - r√©cup√®re `AuthService` via le container DI du backend ;
  - v√©rifie la signature du token (`AuthService.verify_token`) ;
  - refuse l‚Äôacc√®s (`401`) si le token est manquant/invalide, ou (`403`) si `claims.role != "admin"`.
- Les requ√™tes non authentifi√©es sont logg√©es (`warning`) pour audit et retour d‚Äô√©tat (ex: tentative d‚Äôacc√®s par un non-admin).
- Les probes publiques restent ouvertes : `/api/monitoring/health*`, `/health/liveness`, `/health/readiness`.

---

## Endpoints Health Checks

### 1. `/api/monitoring/health` - Health Check Basique

**GET** `/api/monitoring/health`

Healthcheck public simple pour v√©rifier que l'application r√©pond.

**R√©ponse** (200 OK):
```json
{
  "status": "healthy",
  "timestamp": "2025-10-11T13:45:00.000Z",
  "version": "beta-2.1.2"
}
```

**Usage**: Load balancers basiques, monitoring externe simple.

---

### 2. `/api/monitoring/health/detailed` - Health Check D√©taill√©

**GET** `/api/monitoring/health/detailed`

Healthcheck avec m√©triques syst√®me (CPU, RAM, disk).

**R√©ponse** (200 OK):
```json
{
  "status": "healthy",
  "timestamp": "2025-10-11T13:45:00.000Z",
  "system": {
    "platform": "Linux",
    "python_version": "3.11.5",
    "cpu_percent": 12.4,
    "memory": {
      "total_gb": 16.0,
      "available_gb": 8.5,
      "percent_used": 46.9
    },
    "disk": {
      "total_gb": 500.0,
      "free_gb": 235.7,
      "percent_used": 52.9
    }
  }
}
```

**Usage**: Dashboards admin, alerting sur ressources syst√®me.

---

### 3. `/health/liveness` - Liveness Probe K8s

**GET** `/health/liveness`

**Kubernetes liveness probe**: V√©rifie que le processus est vivant et peut traiter des requ√™tes.

**R√©ponse** (200 OK):
```json
{
  "status": "alive",
  "timestamp": "2025-10-11T13:45:00.000Z",
  "uptime_seconds": 3628800
}
```

**Status codes**:
- `200 OK`: Processus vivant
- `503 Service Unavailable`: Processus mort ou bloqu√©

**Configuration K8s** (`deployment.yaml`):
```yaml
livenessProbe:
  httpGet:
    path: /health/liveness
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
```

**Comportement**: Si 3 √©checs cons√©cutifs, Kubernetes red√©marre le pod.

---

### 4. `/health/readiness` - Readiness Probe K8s

**GET** `/health/readiness`

**Kubernetes readiness probe**: V√©rifie que tous les services critiques sont op√©rationnels.

**Services v√©rifi√©s**:
1. **Database** (SQLite/PostgreSQL): Connexion + requ√™te simple (`SELECT 1`)
2. **VectorService** (Chroma/Qdrant): Backend initialis√© + liste collections
3. **LLM Providers** (OpenAI, Anthropic, Google): Clients configur√©s

**R√©ponse** (200 OK - tous services UP):
```json
{
  "overall": "up",
  "timestamp": "2025-10-11T13:45:00.000Z",
  "components": {
    "database": {
      "status": "up"
    },
    "vector_service": {
      "status": "up",
      "backend": "chroma",
      "collections": 3
    },
    "llm_providers": {
      "status": "up",
      "providers": {
        "openai": {"status": "up", "configured": true},
        "anthropic": {"status": "up", "configured": true},
        "google": {"status": "up", "configured": true}
      }
    }
  }
}
```

**R√©ponse** (503 Service Unavailable - au moins 1 service DOWN):
```json
{
  "overall": "degraded",
  "timestamp": "2025-10-11T13:45:00.000Z",
  "components": {
    "database": {
      "status": "up"
    },
    "vector_service": {
      "status": "down",
      "error": "Connection refused"
    },
    "llm_providers": {
      "status": "up",
      "providers": {...}
    }
  }
}
```

**Configuration K8s** (`deployment.yaml`):
```yaml
readinessProbe:
  httpGet:
    path: /health/readiness
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 2
```

**Comportement**: Si 2 √©checs cons√©cutifs, Kubernetes retire le pod du load balancing (pas de trafic).

---

### 3. `/api/system/info` - System Information (Phase P2)

**GET** `/api/system/info`

**Endpoint d√©di√© pour About page** - Informations syst√®me compl√®tes pour la page "√Ä propos".

**Services v√©rifi√©s**:
- Backend version et environnement
- Python version et platform
- System resources (CPU, memory, disk)
- Service status (database, vector, LLM)
- Uptime et performance metrics

**R√©ponse** (200 OK):
```json
{
  "version": {
    "backend": "beta-2.1.2",
    "python": "3.11.5",
    "environment": "production"
  },
  "platform": {
    "system": "Linux",
    "release": "5.15.0",
    "machine": "x86_64",
    "processor": "Intel Xeon"
  },
  "resources": {
    "cpu_percent": 12.4,
    "memory": {
      "total_gb": 16.0,
      "available_gb": 8.5,
      "used_percent": 46.9
    },
    "disk": {
      "total_gb": 500.0,
      "free_gb": 235.7,
      "used_percent": 52.9
    }
  },
  "uptime": {
    "seconds": 3628800,
    "formatted": "42 days, 0 hours",
    "started_at": "2025-09-01T12:00:00Z"
  },
  "services": {
    "database": {
      "status": "up"
    },
    "vector_service": {
      "status": "up",
      "backend": "chroma",
      "collections": 3
    },
    "llm_providers": {
      "status": "up",
      "providers": {
        "openai": {"status": "up", "configured": true},
        "anthropic": {"status": "up", "configured": true}
      }
    }
  },
  "timestamp": "2025-10-17T13:45:00.000Z"
}
```

**Configuration Version**:
- Version d√©finie via variable d'environnement `BACKEND_VERSION` (d√©faut: `beta-2.1.2`)
- Synchronis√©e avec `package.json`, `index.html` et autres fichiers sources
- Utilise `os.getenv("BACKEND_VERSION", "beta-2.1.2")` dans le code (ligne 384)

**Usage**: Page "√Ä propos" de l'application, diagnostics syst√®me, v√©rification d√©ploiement.

---

## Endpoints M√©triques Admin

**Authentification requise**: `Authorization: Bearer <JWT admin>` (impl√©mentation compl√®te depuis novembre 2025).

### 5. `/api/monitoring/metrics` - M√©triques Application

**GET** `/api/monitoring/metrics`

M√©triques agr√©g√©es de l'application (endpoints, s√©curit√©, performance).

**R√©ponse** (200 OK):
```json
{
  "application": {
    "endpoints": {
      "/api/chat": {
        "requests": 1523,
        "errors": 12,
        "avg_latency_ms": 342.5
      },
      "/api/sessions": {
        "requests": 856,
        "errors": 3,
        "avg_latency_ms": 125.7
      }
    }
  },
  "security": {
    "failed_login_attempts": 5,
    "suspicious_patterns": 2,
    "blocked_ips": 0
  },
  "performance": {
    "slow_queries": 12,
    "avg_ai_response_ms": 2450.3
  },
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Dashboard admin global, alerting agr√©g√©.

---

### 6. `/api/monitoring/metrics/export` - Export JSON Complet

**GET** `/api/monitoring/metrics/export`

Export JSON complet de toutes les m√©triques (pour archivage ou analyse externe).

**R√©ponse**: Objet JSON volumineux avec toutes les m√©triques d√©taill√©es.

**Usage**: Archivage journalier, analyse post-mortem, rapports.

---

### 7. `/api/monitoring/metrics/endpoints` - M√©triques par Endpoint

**GET** `/api/monitoring/metrics/endpoints`

M√©triques d√©taill√©es par endpoint API.

**R√©ponse** (200 OK):
```json
{
  "endpoints": {
    "/api/chat": {
      "requests": 1523,
      "errors": 12,
      "avg_latency_ms": 342.5,
      "error_rate": 0.0079
    },
    "/api/sessions": {
      "requests": 856,
      "errors": 3,
      "avg_latency_ms": 125.7,
      "error_rate": 0.0035
    }
  },
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Identifier endpoints lents ou probl√©matiques, tuning performance.

---

### 8. `/api/monitoring/security/alerts` - Alertes S√©curit√©

**GET** `/api/monitoring/security/alerts`

R√©cup√®re les alertes de s√©curit√© (tentatives login, patterns suspects).

**R√©ponse** (200 OK):
```json
{
  "summary": {
    "failed_login_attempts": 5,
    "suspicious_patterns": 2,
    "blocked_ips": 0
  },
  "failed_logins": {
    "user@example.com": 3,
    "hacker@evil.com": 2
  },
  "suspicious_patterns": {
    "sql_injection_attempt": 1,
    "path_traversal_attempt": 1
  },
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Dashboard s√©curit√©, d√©tection intrusions, alerting SOC.

---

### 9. `/api/monitoring/performance/slow-queries` - Requ√™tes Lentes

**GET** `/api/monitoring/performance/slow-queries`

Liste des 50 derni√®res requ√™tes lentes (seuil configurable dans `performance_monitor`).

**R√©ponse** (200 OK):
```json
{
  "slow_queries": [
    {
      "query": "SELECT * FROM sessions WHERE user_id = ?",
      "duration_ms": 1523.4,
      "timestamp": "2025-10-11T13:42:15.000Z"
    },
    {
      "query": "SELECT * FROM messages WHERE session_id = ? ORDER BY created_at",
      "duration_ms": 987.2,
      "timestamp": "2025-10-11T13:40:32.000Z"
    }
  ],
  "count": 50,
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Optimisation requ√™tes DB, d√©tection N+1 queries, indexation.

---

### 10. `/api/monitoring/performance/ai-stats` - Statistiques IA

**GET** `/api/monitoring/performance/ai-stats`

Statistiques des temps de r√©ponse des LLM (OpenAI, Anthropic, Google).

**R√©ponse** (200 OK):
```json
{
  "count": 1234,
  "avg_duration": 2450.3,
  "min_duration": 850.2,
  "max_duration": 8543.7,
  "recent_responses": [
    {
      "provider": "openai",
      "model": "gpt-4",
      "duration_ms": 2340.5,
      "timestamp": "2025-10-11T13:44:55.000Z"
    }
  ],
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Monitoring latence LLM, choix provider optimal, SLA.

---

### 11. `/api/monitoring/alerts/test` - Test Alerting

**POST** `/api/monitoring/alerts/test`

Endpoint de test pour v√©rifier le syst√®me d'alertes (envoie une alerte test).

**R√©ponse** (200 OK):
```json
{
  "message": "Test alert sent to logging system",
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**Usage**: Validation configuration alerting, tests post-d√©ploiement.

---

### 12. `/api/monitoring/metrics/reset` - Reset M√©triques

**DELETE** `/api/monitoring/metrics/reset`

Reset toutes les m√©triques in-memory (utile pour tests ou apr√®s maintenance).

**R√©ponse** (200 OK):
```json
{
  "message": "All metrics reset successfully",
  "timestamp": "2025-10-11T13:45:00.000Z"
}
```

**‚ö†Ô∏è Attention**: Perte de toutes les m√©triques non persist√©es. √Ä utiliser avec pr√©caution.

---

## Int√©gration Kubernetes

### Exemple Deployment complet

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: emergence-backend
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: backend
        image: gcr.io/PROJECT_ID/emergence:latest
        ports:
        - containerPort: 8000

        # Liveness probe: processus vivant?
        livenessProbe:
          httpGet:
            path: /health/liveness
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3  # 3 √©checs = restart pod

        # Readiness probe: services critiques up?
        readinessProbe:
          httpGet:
            path: /health/readiness
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2  # 2 √©checs = retrait du LB

        # Startup probe: d√©marrage initial lent (ChromaDB, etc.)
        startupProbe:
          httpGet:
            path: /health/liveness
            port: 8000
          initialDelaySeconds: 0
          periodSeconds: 5
          failureThreshold: 30  # Max 150s pour d√©marrage
```

### Alerting Prometheus (exemple)

```yaml
groups:
  - name: emergence_health
    rules:
      - alert: PodNotReady
        expr: kube_pod_status_ready{pod=~"emergence-backend-.*"} == 0
        for: 2m
        annotations:
          summary: "Pod √âMERGENCE not ready"

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "Error rate > 5%"
```

---

## Architecture Monitoring

### Composants Internes

Le module `backend.core.monitoring` fournit:

1. **`metrics`**: Collecteur m√©triques application
   - `request_count`: Compteur requ√™tes par endpoint
   - `error_count`: Compteur erreurs par endpoint
   - `latency_sum/count`: Latences moyennes

2. **`security_monitor`**: D√©tection patterns suspects
   - `failed_login_attempts`: Tentatives login par email
   - `suspicious_patterns`: Compteur patterns (SQL injection, etc.)

3. **`performance_monitor`**: Tracking performance
   - `slow_queries`: Liste requ√™tes DB lentes (>500ms)
   - `ai_response_times`: Historique latences LLM

### Helpers

- **`log_structured(level, message, **kwargs)`**: Logging structur√© (JSON) pour agr√©gation
- **`export_metrics_json()`**: Export complet m√©triques en JSON

---

## Configuration

### Variables d'environnement

Aucune variable sp√©cifique pour le monitoring de base. Les composants d√©pendent de:

- `DATABASE_URL`: Connexion DB pour health check database
- `VECTOR_BACKEND`: Type VectorService (chroma/qdrant) pour health check
- Cl√©s API LLM: Pour health check providers (OpenAI, Anthropic, Google)

### Seuils Configurables

Dans `backend.core.monitoring`:

```python
# performance_monitor.py
SLOW_QUERY_THRESHOLD_MS = 500  # Seuil requ√™tes lentes

# security_monitor.py
MAX_FAILED_LOGINS = 5  # Alerting apr√®s 5 tentatives
SUSPICIOUS_PATTERN_THRESHOLD = 10  # Alerting apr√®s 10 patterns
```

---

## Bonnes Pratiques Production

### Kubernetes

1. **Toujours utiliser les 3 probes**:
   - `livenessProbe`: D√©tecte deadlocks
   - `readinessProbe`: Traffic routing intelligent
   - `startupProbe`: G√®re d√©marrages lents (30-60s pour ChromaDB)

2. **Tuning timeouts**:
   - Liveness: `timeoutSeconds: 5` (rapide)
   - Readiness: `timeoutSeconds: 3` (tr√®s rapide, v√©rifie services)
   - Startup: `failureThreshold: 30` (150s max pour boot)

3. **√âviter restart loops**:
   - `initialDelaySeconds` suffisant pour initialisation
   - `failureThreshold` pas trop bas (√©viter false positives)

### Monitoring Externe

1. **Prometheus + Grafana**:
   - Scraper `/metrics` pour m√©triques Prometheus (voir [metrics.md](metrics.md))
   - Dashboard Grafana avec panels pour health checks

2. **Alerting**:
   - PagerDuty/Opsgenie pour alertes critiques (pods down)
   - Slack/Email pour alertes non-critiques (slow queries)

3. **Logging Structur√©**:
   - Centraliser logs JSON avec Loki/CloudWatch
   - Corr√©ler avec m√©triques Prometheus

---

## Limitations Connues

1. **Stub authentification admin**: `verify_admin()` est un placeholder (TODO: impl√©menter vraie auth)
2. **M√©triques in-memory**: Perte au restart (TODO: persistence Redis/PostgreSQL)
3. **Pas de rate limiting**: Endpoints admin non prot√©g√©s contre spam

---

## Roadmap

- **P2.0**: Authentification admin compl√®te (JWT + RBAC)
- **P2.1**: Persistence m√©triques (Redis/PostgreSQL)
- **P2.2**: Rate limiting endpoints admin
- **P3.0**: Dashboard Grafana pr√©-configur√© embarqu√©
- **P3.1**: Int√©gration CloudWatch/DataDog native

---

## R√©f√©rences

- [Metrics](metrics.md) - Endpoints Prometheus pour m√©triques
- [Monitoring Guide](../MONITORING_GUIDE.md) - Guide observabilit√© complet
- [Architecture Components](../architecture/10-Components.md) - D√©tail composants
- [Kubernetes Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)

---

## Changelog

### P1.6 - 2025-11-30
- üîê `verify_admin()` effectif sur tous les endpoints `/api/monitoring/**` (tokens JWT obligatoires, r√¥le `admin` requis)
- üîè `/api/system/info` prot√©g√© (plus accessible publiquement)
- üìì Documentation mise √† jour (section Authentification & S√©curit√© + rappels d‚Äôusage)

### P2.1.2 - 2025-10-17
- **Synchronisation versioning** : `version` maintenant `beta-2.1.2` (ligne 38)
- **Endpoint /api/system/info** : Informations syst√®me compl√®tes pour About page
- Version backend via variable `BACKEND_VERSION` (d√©faut: `beta-2.1.2`)
- Synchronisation avec `package.json`, `index.html` et autres fichiers sources

### P1.5 - 2025-10-11
- Health checks avanc√©s (liveness, readiness, detailed)
- Support Kubernetes probes complet
- Endpoints m√©triques admin (s√©curit√©, performance, AI stats)
- V√©rification Database/VectorService/LLM providers

### P1.0 - 2025-09-15
- Health check basique `/api/monitoring/health`
- M√©triques application initiales
- Security/Performance monitors

