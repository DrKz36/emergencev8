# Voice Feature - TTS/STT avec ElevenLabs & Whisper

## Vue d'ensemble

Le module Voice offre des capacit√©s de synth√®se vocale (TTS) et de reconnaissance vocale (STT) pour permettre aux utilisateurs d'interagir vocalement avec les agents.

**Version:** beta-3.3.16
**Date:** 2025-10-31
**Status:** ‚úÖ TTS op√©rationnel | üöß STT/WebSocket pr√©vu pour v3.4+

## Architecture

### Backend (`src/backend/features/voice/`)

```
voice/
‚îú‚îÄ‚îÄ models.py          # Pydantic models (VoiceServiceConfig, TTSRequest)
‚îú‚îÄ‚îÄ service.py         # VoiceService (synthesize_speech, transcribe_audio)
‚îî‚îÄ‚îÄ router.py          # REST + WebSocket endpoints
```

### Services

#### VoiceService (`service.py`)

**Responsabilit√©s:**
- Synth√®se vocale (TTS) via ElevenLabs API
- Transcription audio (STT) via OpenAI Whisper
- Gestion des streams audio (chunked streaming)
- Int√©gration avec ChatService pour interactions vocales compl√®tes

**M√©thodes principales:**

```python
async def synthesize_speech(self, text: str) -> AsyncGenerator[bytes, None]:
    """
    G√©n√®re un flux audio MP3 √† partir de texte avec ElevenLabs.

    Args:
        text: Texte √† synth√©tiser

    Yields:
        Chunks audio MP3 (bytes)

    Raises:
        HTTPException: Si g√©n√©ration √©choue
    """

async def transcribe_audio(self, audio_data: bytes) -> str:
    """
    Transcrit audio vers texte avec OpenAI Whisper.

    Args:
        audio_data: Donn√©es audio (webm/opus)

    Returns:
        Texte transcrit

    Raises:
        HTTPException: Si transcription √©choue
    """
```

**Configuration (.env):**

```env
# ElevenLabs TTS
ELEVENLABS_API_KEY=sk_...
ELEVENLABS_VOICE_ID=ohItIVrXTBI80RrUECOD  # Voix fran√ßaise naturelle
ELEVENLABS_MODEL_ID=eleven_multilingual_v2

# OpenAI Whisper STT
OPENAI_API_KEY=sk-proj-...
WHISPER_MODEL=whisper-1  # Optionnel (d√©faut: whisper-1)
```

### Endpoints

#### REST - TTS (Op√©rationnel)

**`POST /api/voice/tts`**

G√©n√®re un flux audio MP3 √† partir de texte.

**Request:**
```json
{
  "text": "Bonjour, je suis Anima !"
}
```

**Response:**
- Status: 200
- Content-Type: `audio/mpeg`
- Content-Disposition: `inline`
- Body: Stream MP3 (chunked)

**Erreurs:**
- 400: Texte vide
- 503: VoiceService indisponible
- 500: Erreur g√©n√©ration TTS

**Exemple cURL:**
```bash
curl -X POST https://emergence-app.run.app/api/voice/tts \
  -H "Authorization: Bearer $JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"text": "Test de synth√®se vocale"}' \
  --output test.mp3
```

#### WebSocket - Interaction vocale (Pr√©vu v3.4+)

**`WS /api/voice/ws/{agent_name}?session_id=<uuid>`**

Interaction vocale bi-directionnelle avec un agent.

**Flow:**
1. Client envoie audio (webm/opus bytes)
2. Serveur transcrit via Whisper
3. Serveur g√©n√®re r√©ponse LLM via ChatService
4. Serveur synth√©tise via ElevenLabs
5. Serveur stream audio MP3 au client

**Messages serveur:**
```json
{ "type": "text", "data": "R√©ponse LLM" }
{ "type": "audio", "data": <bytes MP3> }
{ "type": "error", "data": "Message d'erreur" }
```

**Note:** WebSocket vocal non encore utilis√© par l'UI frontend.

## Frontend

### UI Chat (`src/frontend/features/chat/chat-ui.js`)

**Fonctionnalit√©s:**
- ‚úÖ Bouton "√âcouter" sur chaque message d'agent (ic√¥ne speaker)
- ‚úÖ Appel API `/api/voice/tts` avec texte du message
- ‚úÖ Player audio HTML5 flottant (bas droite)
- ‚úÖ Contr√¥les natifs (play/pause/volume/timeline)
- ‚úÖ Cleanup automatique URLs blob apr√®s lecture

**Impl√©mentation:**

```javascript
async _handleListenMessage(button) {
  const text = this._decodeHTML(button.getAttribute('data-message'));
  const response = await apiClient.post('/api/voice/tts', { text });
  const blob = await response.blob();
  const audioUrl = URL.createObjectURL(blob);

  let audio = document.getElementById('chat-audio-player');
  if (!audio) {
    audio = document.createElement('audio');
    audio.id = 'chat-audio-player';
    audio.controls = true;
    audio.style.cssText = 'position: fixed; bottom: 80px; right: 20px; ...';
    document.body.appendChild(audio);
  }

  audio.src = audioUrl;
  audio.play();
}
```

## Provider ElevenLabs

### Caract√©ristiques

- **Model:** `eleven_multilingual_v2`
- **Voice ID:** `ohItIVrXTBI80RrUECOD` (voix fran√ßaise naturelle)
- **Format audio:** MP3, bitrate 128kbps
- **Latency:** ~500-1000ms (streaming)
- **Qualit√©:** Voix naturelle sup√©rieure aux TTS standards (Google, AWS Polly)

### Limites

- **Quota:** 10,000 caract√®res/mois (plan free) / 100,000 caract√®res/mois (plan starter)
- **Rate limit:** 2 requ√™tes/seconde
- **Max text length:** 5000 caract√®res par requ√™te

### Co√ªts (R√©f√©rence)

- **Plan Free:** $0 pour 10k chars/mois
- **Plan Starter:** $5/mois pour 100k chars
- **Plan Creator:** $22/mois pour 500k chars
- **Entreprise:** Custom pricing

## Tests

### Tests Backend

```bash
# Tests unitaires VoiceService
pytest tests/backend/features/test_voice_service.py -v

# Tests d'int√©gration endpoints
pytest tests/backend/features/test_voice_router.py -v
```

### Tests manuels

**TTS via cURL:**
```bash
# Obtenir JWT token
export JWT_TOKEN=$(curl -X POST http://localhost:8080/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "test@example.com", "password": "password"}' \
  | jq -r '.token')

# Tester TTS
curl -X POST http://localhost:8080/api/voice/tts \
  -H "Authorization: Bearer $JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"text": "Bonjour, ceci est un test de synth√®se vocale"}' \
  --output test.mp3

# Lire l'audio
mpv test.mp3  # ou vlc, ffplay, etc.
```

**TTS via UI:**
1. Ouvrir module Dialogue
2. Envoyer message √† un agent
3. Cliquer bouton "√âcouter" (ic√¥ne speaker)
4. Player audio appara√Æt en bas √† droite
5. Audio se joue automatiquement

## Roadmap

### Version actuelle (beta-3.3.16)
- ‚úÖ TTS REST endpoint op√©rationnel
- ‚úÖ Bouton "√âcouter" sur messages agents
- ‚úÖ Player audio flottant
- ‚úÖ Configuration ElevenLabs centralis√©e

### v3.4 - Voice Interaction Compl√®te
- üöß WebSocket vocal bi-directionnel
- üöß UI microphone + enregistrement audio
- üöß Transcription STT Whisper en temps r√©el
- üöß Conversation vocale compl√®te (mains libres)

### v3.5 - Voice Avanc√©e
- üîÆ Voix personnalis√©es par agent (multi-voice)
- üîÆ Voice cloning pour voix custom
- üîÆ Support langues multiples (d√©tection auto)
- üîÆ Mode conversation continue (VAD - Voice Activity Detection)

## D√©pendances

**Backend Python:**
```python
httpx>=0.27.0  # Client HTTP async pour appels ElevenLabs/OpenAI
openai>=1.0.0  # SDK OpenAI (Whisper STT)
```

**APIs externes:**
- ElevenLabs API (TTS)
- OpenAI API (Whisper STT)

## Troubleshooting

### Erreur: VoiceService indisponible (503)

**Cause:** Cl√©s API manquantes dans `.env`

**Solution:**
```bash
# V√©rifier .env contient:
ELEVENLABS_API_KEY=sk_...
OPENAI_API_KEY=sk-proj-...
```

### Erreur: Audio ne se joue pas

**Cause 1:** Autoplay bloqu√© par navigateur

**Solution:** Cliquer manuellement sur play dans le player audio

**Cause 2:** Format audio incompatible

**Solution:** V√©rifier que le navigateur supporte MP3 (tous modernes le supportent)

### Erreur: Rate limit ElevenLabs (429)

**Cause:** Trop de requ√™tes TTS en peu de temps (>2/sec)

**Solution:**
- Impl√©menter throttling c√¥t√© client
- Upgrader plan ElevenLabs si usage √©lev√©

## S√©curit√©

### Points d'attention

- ‚úÖ **Auth JWT requise** - Tous les endpoints voice n√©cessitent authentification
- ‚úÖ **Validation input** - Texte valid√© (max 5000 chars, pas de texte vide)
- ‚úÖ **Rate limiting** - Respecte limites ElevenLabs (2 req/sec)
- ‚úÖ **Pas de secrets expos√©s** - Cl√©s API uniquement c√¥t√© backend
- ‚ö†Ô∏è **Pas de sanitization audio** - Audio g√©n√©r√© non filtr√© (confiance ElevenLabs)

### Recommandations

1. **Monitoring usage** - Logger les requ√™tes TTS pour d√©tecter abus
2. **Rate limiting custom** - Ajouter rate limit applicatif (ex: 10 TTS/min par user)
3. **Quotas utilisateurs** - Limiter caract√®res TTS/jour par utilisateur
4. **Audit logs** - Logger tous les appels voice pour tra√ßabilit√©

## R√©f√©rences

- [ElevenLabs API Documentation](https://elevenlabs.io/docs/api-reference/text-to-speech)
- [OpenAI Whisper Documentation](https://platform.openai.com/docs/guides/speech-to-text)
- [Architecture √âMERGENCE - Contrats API](./architecture/30-Contracts.md#6-voice-api-endpoints)
- [Architecture √âMERGENCE - Composants Backend](./architecture/10-Components.md)
