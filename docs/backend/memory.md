# Memory Feature - Analyzer & Hybrid Retriever

**Modules**:
- `src/backend/features/memory/analyzer.py`
- `src/backend/features/memory/hybrid_retriever.py`
- `src/backend/features/memory/gardener.py`
- `src/backend/features/memory/memory_query_tool.py`

**Version**: V3.9 (Agent Memory Isolation)
**Derni√®re mise √† jour**: 2025-10-17

## Vue d'ensemble

Le syst√®me de m√©moire √âMERGENCE combine deux composants compl√©mentaires:

1. **MemoryAnalyzer**: Analyse s√©mantique des conversations et extraction des pr√©f√©rences utilisateur
2. **HybridRetriever**: Recherche hybride (BM25 + vectorielle) pour am√©liorer la pertinence du RAG

## 1. Memory Analyzer (V3.8)

### Fonctionnalit√©s principales

#### 1.0 Consolidation m√©moire avec feedback temps r√©el (V3.8 - 2025-10-15)

**Nouveaut√©**: Le MemoryGardener envoie d√©sormais des √©v√©nements WebSocket `ws:memory_progress` pour notifier l'avancement en temps r√©el.

**√âv√©nements √©mis**:
- **Phase in_progress**: Notification session par session
  ```json
  {
    "type": "ws:memory_progress",
    "payload": {
      "session_id": "session_123",
      "current": 2,
      "total": 5,
      "phase": "extracting_concepts",
      "status": "in_progress"
    }
  }
  ```

- **Phase completed**: R√©sum√© final de la consolidation
  ```json
  {
    "type": "ws:memory_progress",
    "payload": {
      "session_id": "session_123",
      "current": 5,
      "total": 5,
      "phase": "completed",
      "status": "completed",
      "consolidated_sessions": 5,
      "new_items": 23
    }
  }
  ```

**Phases disponibles**:
- `extracting_concepts`: Extraction concepts/entit√©s/faits
- `analyzing_preferences`: Classification pr√©f√©rences/intentions
- `vectorizing`: Sauvegarde ChromaDB
- `completed`: Consolidation termin√©e

**Impact UX**:
- Barre de progression affich√©e dans le frontend (Centre M√©moire)
- Labels traduits : "Extraction des concepts... (2/5 sessions)"
- Message final : "‚úì Consolidation termin√©e : 5 sessions, 23 nouveaux items"
- Dur√©e estim√©e affich√©e : 30s-2min selon volume

**Impl√©mentation**: Voir [gardener.py:572-695](../../src/backend/features/memory/gardener.py#L572-L695)

#### 1.1 Analyse s√©mantique multi-provider

Extraction automatique de:
- **Summary**: R√©sum√© concis de la conversation (2-3 phrases)
- **Concepts**: 3-5 concepts cl√©s abord√©s (sp√©cifiques, ex: "√©thique de l'IA dans le diagnostic m√©dical")
- **Entities**: Entit√©s nomm√©es (noms propres, lieux, titres)

**Fallback cascade** pour garantir la fiabilit√©:
```
neo_analysis (GPT-4o-mini, rapide)
  ‚Üì √©chec
nexus (Anthropic Claude, fiable)
  ‚Üì √©chec
anima (OpenAI GPT-4, derni√®re chance)
  ‚Üì √©chec
offline_analysis (heuristique, tests/d√©gradation)
```

**Timeout**: 30s par provider pour √©viter blocages ind√©finis.

#### 1.2 Extraction pr√©f√©rences/intentions (Phase P1)

Extraction automatique via `PreferenceExtractor`:

**Types de pr√©f√©rences**:
- `preference`: Pr√©f√©rence g√©n√©rale ("pr√©f√®re Python pour le scripting")
- `intent`: Intention d√©clar√©e ("veut apprendre FastAPI")
- `constraint`: Contrainte/limitation ("√©viter les frameworks lourds")

**Seuils de confiance**:
- Haute confiance (‚â•0.6): Injection automatique dans RAG
- Moyenne confiance (0.3-0.6): Sauvegard√© mais non inject√©
- Basse confiance (<0.3): Ignor√©

**M√©tadonn√©es enrichies**:
```python
{
    "user_id": "user_123",
    "type": "preference",
    "topic": "programmation",
    "confidence": 0.85,
    "sentiment": "positive",
    "timeframe": "permanent",
    "created_at": "2025-10-11T13:45:00Z",
    "thread_id": "session_456",
    "source": "preference_extractor_v1.2"
}
```

#### 1.3 Cache analyses (TTL 1h)

**Performance optimis√©e**:
- Cache key: `memory_analysis:{session_id}:{history_hash}`
- TTL: 1 heure
- √âviction agressive: Garde top 50 entr√©es les plus r√©centes quand >80 entr√©es

**Thread-safety**:
- Utilise `asyncio.Lock` pour acc√®s concurrent s√©curis√©
- √âvite race conditions (Bug #3 fix)

**M√©triques**:
```
memory_analysis_cache_hits_total
memory_analysis_cache_misses_total
memory_cache_size (gauge)
```

#### 1.4 M√©triques Prometheus compl√®tes

**Succ√®s/√âchecs par provider**:
```
memory_analysis_success_total{provider="neo_analysis|nexus|anima"}
memory_analysis_failure_total{provider="...", error_type="TimeoutError|..."}
```

**Latence analyses**:
```
memory_analysis_duration_seconds{provider="..."}
# Buckets: [0.5, 1.0, 2.0, 4.0, 6.0, 10.0, 15.0, 20.0, 30.0]
```

**√âchecs extraction pr√©f√©rences (HOTFIX P1.3)**:
```
memory_preference_extraction_failures_total{reason="user_identifier_missing|extraction_error|persistence_error"}
```

### API publique

#### `analyze_session_for_concepts(session_id, history, force=False, user_id=None)`

Analyse une session compl√®te et persiste les r√©sultats dans la base de donn√©es.

**Param√®tres**:
- `session_id` (str): ID session √† analyser
- `history` (List[Dict]): Historique messages (format: `[{"role": "user|assistant", "content": "..."}]`)
- `force` (bool): Force nouvelle analyse m√™me si d√©j√† analys√©e
- `user_id` (str, optionnel): ID utilisateur pour extraction pr√©f√©rences

**Retour**: Dict avec `summary`, `concepts`, `entities`

**Side-effects**:
- Sauvegarde dans DB (table `sessions`)
- Extraction et sauvegarde pr√©f√©rences dans ChromaDB
- Invalidation cache pr√©f√©rences (MemoryContextBuilder)

#### `analyze_history(session_id, history)`

Analyse un historique sans persister dans la DB (mode thread-only).

**Usage**: Analyses ponctuelles, tests, ou threads temporaires.

#### `analyze_session_async(session_id, force=False, callback=None)`

Version non-bloquante utilisant la `MemoryTaskQueue`.

**Usage**: Enqueue l'analyse pour ex√©cution asynchrone en arri√®re-plan.

### Configuration

**Variables d'environnement**:
- `MEMORY_ANALYZER_ALLOW_OFFLINE`: Active mode offline (fallback heuristique)
- `PYTEST_CURRENT_TEST`: D√©tection automatique mode test (offline auto)
- `EMERGENCE_KNOWLEDGE_COLLECTION`: Collection ChromaDB (d√©faut: `emergence_knowledge`)

**Param√®tres internes**:
- Cache TTL: 1 heure
- Cache max size: 100 entr√©es
- Cache eviction threshold: 80 entr√©es
- Timeout LLM: 30 secondes

### Int√©gration

```python
from backend.features.memory.analyzer import MemoryAnalyzer

# Initialisation
analyzer = MemoryAnalyzer(
    db_manager=db_manager,
    chat_service=chat_service,
    enable_offline_mode=False
)

# Analyse avec extraction pr√©f√©rences
result = await analyzer.analyze_session_for_concepts(
    session_id="session_123",
    history=[
        {"role": "user", "content": "J'aime Python pour le scripting"},
        {"role": "assistant", "content": "Python est excellent pour √ßa!"}
    ],
    force=False,
    user_id="user_456"  # Important pour extraction pr√©f√©rences
)

# R√©sultat
{
    "summary": "Discussion sur Python pour le scripting",
    "concepts": ["Python", "scripting", "langage de programmation"],
    "entities": ["Python"]
}
```

---

## 2. Hybrid Retriever (V1.0)

### Fonctionnalit√©s principales

#### 2.1 Scoring hybride BM25 + Vectoriel

**Approche**: Combine recherche lexicale (BM25) et s√©mantique (embeddings) pour am√©liorer la pertinence.

**Formule de fusion**:
```python
hybrid_score = (1 - alpha) √ó bm25_score + alpha √ó vector_score
```

**Param√®tres par d√©faut**:
- `alpha = 0.5`: √âquilibre 50/50 entre BM25 et vectoriel
- `score_threshold = 0.0`: Pas de filtrage par d√©faut
- `top_k = 5`: Retourne top 5 r√©sultats

#### 2.2 BM25 Scorer (Okapi BM25)

Algorithme de ranking lexical bas√© sur TF-IDF am√©lior√©.

**Formule BM25**:
```
score(D, Q) = Œ£ IDF(qi) ¬∑ (f(qi, D) ¬∑ (k1 + 1)) / (f(qi, D) + k1 ¬∑ (1 - b + b ¬∑ |D| / avgdl))
```

**Param√®tres**:
- `k1 = 1.5`: Contr√¥le saturation du term frequency
- `b = 0.75`: Contr√¥le importance de la longueur du document

**Avantages BM25**:
- Capture les matchs lexicaux exacts (mots-cl√©s)
- Robuste aux synonymes et variations orthographiques
- Rapide (pas d'embedding n√©cessaire)

#### 2.3 Fusion des scores

**Processus**:
1. Normalisation scores BM25 dans [0, 1]
2. Normalisation scores vectoriels (distance ‚Üí similarit√©)
3. Pond√©ration selon `alpha`
4. Filtrage par `score_threshold`
5. Tri par score d√©croissant
6. Retour top_k r√©sultats

**D√©tails par r√©sultat**:
```python
{
    "text": "contenu du document",
    "score": 0.85,          # Score hybride final
    "bm25_score": 0.78,     # Composante BM25
    "vector_score": 0.92,   # Composante vectorielle
    "metadata": {...}       # M√©tadonn√©es du document
}
```

#### 2.4 M√©triques RAG

Tracking automatique via `RAGMetricsTracker`:

```
rag_queries_hybrid_total{status="success|error"}
rag_results_count (histogram)
rag_avg_score (gauge)
rag_results_filtered_total{reason="below_threshold|..."}
```

### API publique

#### `hybrid_query(vector_service, collection, query_text, ...)`

Helper pour recherche hybride compl√®te sur une collection.

**Param√®tres**:
- `vector_service`: Instance VectorService
- `collection`: Collection Chroma/Qdrant
- `query_text` (str): Requ√™te utilisateur
- `n_results` (int): Nombre de r√©sultats (d√©faut: 5)
- `where_filter` (dict, optionnel): Filtres m√©tadonn√©es
- `alpha` (float): Poids vectoriel (d√©faut: 0.5)
- `score_threshold` (float): Seuil minimum (d√©faut: 0.0)
- `bm25_k1` (float): Param√®tre BM25 (d√©faut: 1.5)
- `bm25_b` (float): Param√®tre BM25 (d√©faut: 0.75)

**Retour**: Liste de r√©sultats hybrides avec scores d√©taill√©s

#### `HybridRetriever.retrieve(query, corpus, vector_results, ...)`

M√©thode bas-niveau pour fusion scores BM25 + vectoriels.

**Usage avanc√©**: Permet de customiser le corpus BM25 et pr√©-calculer les r√©sultats vectoriels.

### Configuration

**Tuning alpha** (poids vectoriel):
- `alpha = 0.0`: Full BM25 (lexical pur)
- `alpha = 0.5`: √âquilibre (recommand√©)
- `alpha = 1.0`: Full vectoriel (s√©mantique pur)

**Tuning score_threshold**:
- `0.0`: Pas de filtrage (retourne tous les top_k)
- `0.3-0.5`: Filtrage mod√©r√© (√©limine r√©sultats peu pertinents)
- `0.7+`: Filtrage strict (mode haute pr√©cision)

**Tuning BM25**:
- `k1 = 1.5` (standard): Bon √©quilibre pour la plupart des corpus
- `b = 0.75` (standard): Normalisation longueur documents

### Int√©gration

```python
from backend.features.memory.hybrid_retriever import hybrid_query

# Recherche hybride compl√®te
results = hybrid_query(
    vector_service=vector_service,
    collection=knowledge_collection,
    query_text="Comment configurer FastAPI avec Uvicorn?",
    n_results=5,
    where_filter={"user_id": "user_123"},
    alpha=0.5,  # √âquilibre BM25/vectoriel
    score_threshold=0.3  # Filtrage mod√©r√©
)

# R√©sultats
for r in results:
    print(f"Score: {r['score']:.3f} (BM25: {r['bm25_score']:.3f}, Vector: {r['vector_score']:.3f})")
    print(f"Text: {r['text'][:100]}...")
```

### Performance

**Benchmarks P1.5**:

| Op√©ration | Latence | Notes |
|-----------|---------|-------|
| BM25 scoring | ~10ms | Corpus 100 docs |
| Vectoriel | ~50ms | ChromaDB query top 10 |
| Fusion | ~2ms | Normalisation + tri |
| **Total** | **~60ms** | Top 5 r√©sultats hybrides |

**Trade-offs**:
- BM25 rapide mais moins s√©mantique
- Vectoriel plus lent mais meilleure compr√©hension contexte
- Hybride: meilleur compromis pr√©cision/vitesse

## Limitations connues

### MemoryAnalyzer
1. **Timeout fixe 30s**: Peut √™tre insuffisant pour conversations tr√®s longues (>10k tokens)
2. **Pas de batch processing**: Analyse sessions une par une (pas de parallelisation)
3. **Cache non distribu√©**: Chaque instance a son propre cache (probl√®me multi-instances)

### HybridRetriever
1. **Corpus full reload**: BM25 reconstruit l'index √† chaque query (pas de persistence)
2. **Pas de reranking cross-encoder**: Pas de r√©ordonnancement final (phase P2+)
3. **Alpha statique**: Pas d'adaptation dynamique selon la requ√™te

## Roadmap

### MemoryAnalyzer
- **P2.0**: Batch processing pour analyses multiples
- **P2.1**: Cache distribu√© Redis pour multi-instances
- **P2.2**: Incremental analysis (analyse uniquement nouveaux messages)

### HybridRetriever
- **P2.0**: Persistence index BM25 (√©viter reconstruction)
- **P2.1**: Cross-encoder reranking (LLM final pass)
- **P2.2**: Dynamic alpha tuning bas√© sur query type

## R√©f√©rences

- [Chat Feature](chat.md) - MemoryContextBuilder (utilise HybridRetriever)
- [Metrics](metrics.md) - Endpoints Prometheus pour m√©triques RAG
- [VectorService](../architecture/10-Components.md#vectorservice) - Recherche vectorielle
- [Monitoring Guide](../MONITORING_GUIDE.md) - Observabilit√© compl√®te

## 3. Memory Query Tool (timeline agents)

**Module** : `src/backend/features/memory/memory_query_tool.py`

### 3.1 Liste des sujets discut√©s

**API** :
```python
list_discussed_topics(
    user_id: str,
    timeframe: str = "week",
    limit: int = 50,
    min_mention_count: int = 1,
    agent_id: Optional[str] = None  # üÜï V3.9
)
```

**Param√®tres** :
- `user_id` : Identifiant utilisateur
- `timeframe` : P√©riode (`today`, `week`, `month`, `all`)
- `limit` : Nombre maximum de sujets
- `min_mention_count` : Nombre minimum de mentions
- `agent_id` : üÜï **Filtrage par agent** pour isolation m√©moire

**Retour** : Liste de `TopicSummary` (dates ISO, conversations, thread_ids, vitalit√©)

### 3.2 Timeline conversationnelle

**API** :
```python
get_conversation_timeline(
    user_id: str,
    limit: int = 120,
    agent_id: Optional[str] = None  # üÜï V3.9
)
```

**Fonctionnement** :
- Regroupe sujets en 4 fen√™tres temporelles : `this_week`, `last_week`, `this_month`, `older`
- Tri chronologique (plus r√©cent d'abord) : `last_date` ‚Üí `first_date`
- Cutoffs calcul√©s backend (1 sem, 2 sem, 30 jours)
- üÜï **Filtrage par agent_id** pour contexte isol√©

### 3.3 Formatage naturel pour les LLMs
- `format_timeline_natural_fr(timeline)` retourne un bloc Markdown pr√™t pour injection dans le prompt :
  ```markdown
  ### Historique des sujets abord√©s

  **Cette semaine:**
  - CI/CD pipeline (5 oct 14h32, 8 oct 09h15) - 3 conversations
    ‚îî‚îÄ Automatisation d√©ploiement GitHub Actions
  ```
- Utilis√© par les agents pour r√©pondre aux questions ¬´ qu‚Äôavons-nous abord√© r√©cemment ? ¬ª.

### 3.4 Donn√©es requises
- S‚Äôappuie sur `VectorService` et la collection `emergence_knowledge`.
- Les consolidations m√©moires doivent injecter `first_date`, `last_date`, `summary`, `thread_ids`, `mention_count`.

## Changelog

### V3.9 (Agent Memory Isolation) - 2025-10-17
- üÜï **Isolation m√©moire par agent**: Filtrage `agent_id` dans `MemoryQueryTool`
- üÜï **Timeline par agent**: `get_conversation_timeline()` et `list_discussed_topics()` supportent `agent_id`
- üÜï **Contexte agent-specific**: Chaque agent (AnimA, Neo, Nexus) a sa propre timeline
- üÜï **Anti-hallucination**: Message explicite quand timeline vide pour √©viter fabrication

### V3.8 (UX Improvements) - 2025-10-15
- **Feedback temps r√©el**: √âv√©nements WebSocket `ws:memory_progress` pour suivi consolidation
- **Barre de progression frontend**: Affichage (X/Y sessions) avec phases traduites
- **UX am√©lior√©e**: Bouton renomm√© "Consolider m√©moire" + tooltip explicatif
- **Documentation enrichie**: Tutoriel + guide technique mis √† jour

### V3.7 (P1) - 2025-10-11
- Extraction pr√©f√©rences/intentions avec PreferenceExtractor
- Fallback cascade LLM (neo ‚Üí nexus ‚Üí anima)
- Cache thread-safe avec asyncio.Lock
- M√©triques √©checs extraction pr√©f√©rences (HOTFIX P1.3)

### V3.6 - 2025-09-20
- Cache analyses TTL 1h avec √©viction agressive
- Timeout 30s par provider
- M√©triques Prometheus succ√®s/√©checs/latence

### V1.0 (HybridRetriever) - 2025-10-05
- Impl√©mentation BM25 + vectoriel
- M√©triques RAG via RAGMetricsTracker
- Helper `hybrid_query()` pour usage simplifi√©
