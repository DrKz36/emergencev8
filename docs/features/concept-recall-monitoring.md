# Concept Recall - Plan Monitoring & M√©triques

**Date** : 2025-10-04
**Status** : üìã Planification

## Objectif

Impl√©menter un syst√®me de monitoring pour suivre l'efficacit√© et l'utilisation du syst√®me de concept recall.

## M√©triques √† impl√©menter

### 1. M√©triques de d√©tection

#### Compteurs
- `concept_recall_detections_total` (counter)
  - Labels: `user_id`, `similarity_range` (0.5-0.6, 0.6-0.7, 0.7-0.8, 0.8+)
  - Description: Nombre total de d√©tections de concepts r√©currents

- `concept_recall_events_emitted_total` (counter)
  - Labels: `user_id`
  - Description: Nombre d'√©v√©nements WebSocket √©mis

#### Histogrammes
- `concept_recall_similarity_score` (histogram)
  - Buckets: [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  - Description: Distribution des scores de similarit√©

- `concept_recall_detection_latency_seconds` (histogram)
  - Buckets: [0.01, 0.05, 0.1, 0.5, 1.0, 2.0]
  - Description: Temps de d√©tection (recherche vectorielle + filtrage)

#### Gauges
- `concept_recall_concepts_total` (gauge)
  - Description: Nombre total de concepts dans le vector store

- `concept_recall_active_threads_count` (gauge)
  - Labels: `user_id`
  - Description: Nombre de threads avec concepts d√©tect√©s

### 2. M√©triques de qualit√©

#### Compteurs
- `concept_recall_false_positives_total` (counter)
  - Labels: `user_id`
  - Description: D√©tections ignor√©es par l'utilisateur (bouton "Ignorer")

- `concept_recall_interactions_total` (counter)
  - Labels: `user_id`, `action` (view_history, dismiss, auto_hide)
  - Description: Interactions utilisateur avec les banners

#### Taux
- `concept_recall_precision_rate` (gauge, calcul√©)
  - Formule: `(detections - false_positives) / detections`
  - Description: Pr√©cision du syst√®me (1.0 = parfait)

### 3. M√©triques de performance

#### Histogrammes
- `concept_recall_vector_search_duration_seconds` (histogram)
  - Description: Dur√©e recherche vectorielle ChromaDB

- `concept_recall_json_decode_duration_seconds` (histogram)
  - Description: Dur√©e d√©codage JSON thread_ids

### 4. M√©triques m√©tier

#### Compteurs
- `concept_recall_cross_thread_detections_total` (counter)
  - Labels: `thread_count_range` (2, 3-5, 6-10, 10+)
  - Description: D√©tections cross-thread par plage

- `concept_recall_concept_reuse_total` (counter)
  - Labels: `user_id`
  - Description: Concepts r√©utilis√©s (mention_count > 1)

## Impl√©mentation

### Phase 1: Infrastructure (2h)

1. **Cr√©er module metrics** : `src/backend/features/memory/metrics.py`
   ```python
   from prometheus_client import Counter, Histogram, Gauge

   # Compteurs
   DETECTIONS = Counter(
       'concept_recall_detections_total',
       'Total concept recall detections',
       ['user_id', 'similarity_range']
   )

   # Histogrammes
   SIMILARITY_SCORE = Histogram(
       'concept_recall_similarity_score',
       'Similarity score distribution',
       buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
   )

   # ... autres m√©triques
   ```

2. **Int√©grer dans ConceptRecallTracker**
   - Importer module metrics
   - Ajouter instrumentation apr√®s chaque d√©tection
   - Logger m√©triques dans les logs structur√©s

3. **Exposer endpoint** : `GET /api/metrics` (Prometheus format)

### Phase 2: Collecte (1h)

1. **Instrumenter points cl√©s** :
   - `detect_recurring_concepts()` ‚Üí d√©tections + latence
   - `_update_mention_metadata()` ‚Üí r√©utilisation
   - `_emit_concept_recall_event()` ‚Üí √©v√©nements WS

2. **Ajouter labels contextuels** :
   - `similarity_range` : Cat√©goriser scores (0.5-0.6, 0.6-0.7, etc.)
   - `thread_count_range` : Plages de threads (2, 3-5, 6-10, 10+)

### Phase 3: Visualisation (2h)

1. **Tableau de bord Grafana** :
   - Panel d√©tections/heure (time series)
   - Heatmap scores de similarit√©
   - Top utilisateurs avec d√©tections
   - Taux de pr√©cision (gauge)

2. **Alertes Prometheus** :
   ```yaml
   - alert: ConceptRecallLowPrecision
     expr: concept_recall_precision_rate < 0.6
     for: 1h
     annotations:
       summary: "Precision below 60% for 1h"

   - alert: ConceptRecallHighLatency
     expr: histogram_quantile(0.95, concept_recall_detection_latency_seconds) > 1.0
     for: 5m
     annotations:
       summary: "P95 latency > 1s"
   ```

## Tests

### Tests unitaires
```python
# tests/backend/features/test_concept_recall_metrics.py

async def test_metrics_increment_on_detection():
    before = DETECTIONS._value.get()
    await tracker.detect_recurring_concepts(...)
    after = DETECTIONS._value.get()
    assert after > before

async def test_similarity_histogram_buckets():
    # V√©rifier distribution dans buckets corrects
    pass
```

### Tests d'int√©gration
- V√©rifier endpoint `/api/metrics` retourne format Prometheus
- Simuler 100 d√©tections, v√©rifier agr√©gations

## Checklist de d√©ploiement

- [ ] Cr√©er `src/backend/features/memory/metrics.py`
- [ ] Instrumenter `ConceptRecallTracker`
- [ ] Ajouter endpoint `/api/metrics`
- [ ] Cr√©er tests unitaires
- [ ] Configurer Prometheus scraping (si disponible)
- [ ] Cr√©er dashboard Grafana (optionnel)
- [ ] Documenter m√©triques dans README

## R√©f√©rences

- [Prometheus Python Client](https://github.com/prometheus/client_python)
- [Best practices metrics naming](https://prometheus.io/docs/practices/naming/)
- [ChromaDB performance](https://docs.trychroma.com/usage-guide#performance)

## Notes

- **Opt-in** : M√©triques d√©sactiv√©es par d√©faut (`CONCEPT_RECALL_METRICS_ENABLED=false`)
- **Privacy** : Hash user_id dans labels Prometheus
- **R√©tention** : Recommand√© 30 jours (Prometheus) pour analyse tendances
