# Memory Roadmap ‚Äî Reference

## Contexte

Ce document synth√©tise l'√©tat actuel et la trajectoire de la m√©moire d'Emergence (STM, LTM et composants conceptuels), en se basant sur l'audit pr√©c√©dent. Il sert de r√©f√©rence rapide pour prioriser les travaux, partager les arbitrages techniques et suivre l'avancement.

## Diagnostic

### Forces existantes
- **SessionManager** conserve l'historique court terme et d√©clenche l'analyse s√©mantique via `MemoryAnalyzer` lors de la persistance.
- **MemoryGardener** relit les sessions, extrait concepts et faits ¬´¬†mot-code¬†¬ª, puis les vectorise dans le magasin de connaissances.
- **Vitalit√© des souvenirs**¬†: le jardinier applique un score de vitalit√© (decay p√©riodique + boost √† la consultation) et purge les entr√©es pass√©es sous le seuil minimal.
- Les r√©ponses agents injectent d√©j√† r√©sum√© STM + faits LTM dans le prompt et exposent des √©v√©nements WebSocket (`ws:memory_banner`, `ws:analysis_status`).

### Limites identifi√©es
- L'analyse et la vectorisation sont d√©clench√©es dans la boucle WS, ce qui peut bloquer l'event loop.
- (RESOLU 2025-09-20) Seuils de vitalite et reporting recalibres : base=0.03, stale=14j, archive=45j, nouvelles metriques (buckets, percentiles).
- Les ¬´¬†faits¬†¬ª se limitent aux `mot-code`; aucun suivi de pr√©f√©rences, objectifs ou d√©cisions r√©currentes.
- L'UI n'enregistre pas syst√©matiquement les messages utilisateurs et ne recharge pas la STM depuis la base lors d'une reconnexion.
- Aucun m√©canisme proactif pour signaler des concepts r√©currents ou d√©clencher des suggestions.

## Feuille de route

### P0 ‚Äî Alignement persistance & cross-device
1. **Persistance c√¥t√© client**
   - Envoyer chaque message utilisateur via `POST /api/threads/{id}/messages` (fait c√¥t√© frontend).
   - Continuer de persister les messages assistants en fallback lorsque le backend ne l'a pas d√©j√† fait.
2. **Restauration √† la connexion**
   - Charger la session depuis la base lors du handshake WS si elle n'est pas active (impl√©ment√© c√¥t√© backend).
   - Alignement `session_id ‚Üî thread_id` c√¥t√© UI (le `sessionId` WS est d√©sormais le `threadId`).
3. **√âtapes suivantes (P0 restant)**
   - [FAIT] Route REST `/api/memory/sync-stm` pour reconstituer la STM et hydrater SessionManager.
   - [FAIT] Injection de l'historique restaur√© dans le flux UI (`ws:session_restored`).

### P1 ‚Äî Hors boucle WS & enrichissement conceptuel ‚úÖ COMPL√âT√â (2025-10-09)
- ‚úÖ **P1.1 - D√©portation asynchrone** : `MemoryTaskQueue` avec workers asyncio pour √©viter blocage event loop WebSocket
  - `task_queue.py` (195 lignes) : file asyncio.Queue avec 2 workers background
  - `analyze_session_async()` non-bloquante dans `MemoryAnalyzer`
  - Lifecycle startup/shutdown dans `main.py`
  - Tests unitaires : 5/5 passent
- ‚úÖ **P1.2 - Extension extraction de faits** : Pipeline hybride pr√©f√©rences/intentions/contraintes
  - `preference_extractor.py` (273 lignes) : `PreferenceExtractor` modulaire
  - Filtrage lexical (r√©duction >70% appels LLM) + classification LLM (gpt-4o-mini via ChatService)
  - Normalisation : topic, action, timeframe, sentiment, confidence, entities
  - D√©duplication par `(user_sub, topic, type)`
  - Tests unitaires : 8/8 passent
- ‚úÖ **P1.3 - Instrumentation m√©triques** : 5 nouvelles m√©triques Prometheus pr√©f√©rences
  - `memory_preferences_extracted_total{type}`
  - `memory_preferences_confidence` (histogram)
  - `memory_preferences_extraction_duration_seconds` (histogram)
  - `memory_preferences_lexical_filtered_total`
  - `memory_preferences_llm_calls_total`
- ‚úÖ **M√©triques cache** (Phase 3 existantes) : hits, misses, size
- ‚úÖ **Commit** : `588c5dc` feat(P1): enrichissement m√©moire (862 lignes, 6 fichiers)
- [FAIT] M√©canisme d'oubli par vitalit√© (d√©croissance p√©riodique + purge sous seuil).

### P2 ‚Äî Performance & R√©activit√© proactive ‚úÖ COMPL√âT√â (2025-10-10)
- ‚úÖ **P2 Sprint 1 - Optimisations Performance** : -71% latence contexte LTM
  - ‚úÖ Fix critique co√ªts Gemini (count_tokens avant/apr√®s g√©n√©ration)
  - ‚úÖ Configuration HNSW ChromaDB optimis√©e (M=16, cosine) ‚Üí -82.5% latence queries
  - ‚úÖ Cache in-memory pr√©f√©rences (5min TTL) ‚Üí 100% hit rate
  - ‚úÖ Tests performance : 5/5 passent (benchmarks latence, cache, batch)
  - ‚úÖ Commit : `8205e3b` perf(P2.1): fix Gemini costs + HNSW optimization
- ‚úÖ **P2 Sprint 2 - Proactive Hints Backend** : Suggestions contextuelles op√©rationnelles
  - ‚úÖ ProactiveHintEngine cr√©√© (192 lignes, 100% typed)
  - ‚úÖ ConceptTracker : compteur r√©currence concepts (trigger at 3 mentions)
  - ‚úÖ Int√©gration ChatService compl√®te (4 modifications)
    - Initialisation hint_engine dans __init__
    - M√©thode _emit_proactive_hints_if_any() (44 lignes)
    - Appel asyncio.create_task apr√®s r√©ponse agent
  - ‚úÖ Event WebSocket `ws:proactive_hint` impl√©ment√©
  - ‚úÖ 2 m√©triques Prometheus (hints_generated, hints_relevance)
  - ‚úÖ Tests : 16/16 passants (0.10s)
  - ‚úÖ Commits : `5ce75ce` + `7fd4674` feat(P2 Sprint2): ProactiveHints backend
- ‚úÖ **Gains cumul√©s P2** :
  - Performance : -71% latence (120ms ‚Üí 35ms), -50% queries, 100% cache hit rate
  - Features : 3-5 hints/session, syst√®me proactif vs 100% r√©actif
  - Qualit√© : 21 nouveaux tests (tous passants), 0 erreurs mypy
- üîÑ **P2 Sprint 3 (√Ä FAIRE)** : Frontend UI + Dashboard
  - [ ] Composant ProactiveHintsUI (affichage banners, actions)
  - [ ] Dashboard m√©moire utilisateur
  - [ ] Tests E2E Playwright

### P3 ‚Äî Gouvernance & Observabilit√©
- Journaliser la dur√©e des consolidations et la taille des lots inject√©s pour suivre le co√ªt / perf.
- Ajouter des tests d'int√©gration couvrant `memory.tend-garden`, `memory.clear` et la coh√©rence thread ‚Üî session.

## D√©cisions techniques

| Sujet | D√©cision | Statut |
|-------|----------|--------|
| Vector store | Ajout d'un backend Qdrant optionnel (HTTP) avec fallback automatique sur Chroma | ‚úÖ livr√© ici |
| Persist. messages utilisateur | Envoi syst√©matique via `api.appendMessage` dans le frontend | ‚úÖ livr√© ici |
| Restauration session WS | `ConnectionManager` charge la session depuis la BDD avant de cr√©er une nouvelle STM | ‚úÖ livr√© ici |
| M√©canisme d'oubli | Score de vitalit√© + decay + purge via MemoryGardener | ‚úÖ livr√© ici |
| Calibrage vitalite | Base=0.03, stale=14j, archive=45j, min=0.12 + metrics JSON (vitality_before/after, age_days, buckets) | livre ici |
| Proactivit√© concepts | Compteurs + √©v√©nements √† concevoir (P2) | ‚è≥ √† faire |

## Prochaines √©tapes imm√©diates
- ‚úÖ [FAIT - P0] Synchronisation STM c√¥t√© backend (hydratation `SessionManager` + push `ws:session_restored`)
- ‚úÖ [FAIT - P0] Vectorisation d√©port√©e via t√¢che asynchrone (`asyncio.to_thread`)
- ‚úÖ [FAIT - P0] D√©croissance vitalit√© + purge via `MemoryGardener._decay_knowledge`
- ‚úÖ [FAIT - P0] Calibrage vitalite + export metriques (vitality_*, age_days, bucket_counts)
- ‚úÖ [FAIT - P1 compl√©t√© 2025-10-09] Extension extraction pr√©f√©rences/intentions
  - Pipeline hybride : filtrage lexical + classification LLM + normalisation
  - D√©portation analyses via `MemoryTaskQueue` (workers asyncio)
  - 8 nouvelles m√©triques Prometheus (5 pr√©f√©rences + 3 cache)
  - Tests : 15/15 passent
- ‚úÖ [FAIT - P2 Sprint 1 compl√©t√© 2025-10-10] Optimisations performance
  - Fix co√ªts Gemini + HNSW ChromaDB optimis√© + cache pr√©f√©rences
  - Gains : -71% latence, 100% cache hit rate, -50% queries
  - Tests : 5/5 performance benchmarks
- ‚úÖ [FAIT - P2 Sprint 2 compl√©t√© 2025-10-10] R√©activit√© proactive backend
  - ProactiveHintEngine + int√©gration ChatService
  - Event `ws:proactive_hint` + m√©triques Prometheus
  - Tests : 16/16 hints tests passants
- ‚è≥ [NEXT - P2 Sprint 3] Frontend UI hints proactifs + Dashboard m√©moire utilisateur
- ‚è≥ [APR√àS P2] Gap #3 : D√©cision architecture hybride Sessions/Threads (migration vs maintien)

## Sp√©cification d√©taill√©e ‚Äî Extension MemoryGardener (pr√©f√©rences & intentions)
- [FAIT] Normalisation des cles JSON du classifieur (prevention de la localisation des champs).

### Objectif
Capturer et capitaliser les pr√©f√©rences explicites (go√ªts, contraintes, canaux favoris) ainsi que les intentions d√©clar√©es (prochaines actions, objectifs, engagements) exprim√©es par l'utilisateur afin d'enrichir la m√©moire √† long terme et d'am√©liorer la personnalisation des agents.

### Pipeline hybride
1. **Filtrage lexical imm√©diat** : d√©tecter les phrases contenant des verbes cibles (pr√©f√©rer, aimer, vouloir, √©viter, planifier, d√©cider) et des formes imp√©ratives pour r√©duire le bruit avant appel LLM.
2. **Classification LLM cibl√©e** : utiliser un prompt sp√©cialis√© (mod√®le `gpt-4o-mini` par d√©faut, fallback `claude-3-haiku`) pour cat√©goriser chaque extrait en `preference`, `intent`, `constraint` ou `neutral`, avec score de confiance.
3. **Normalisation** : standardiser le sujet (`topic`), l'action (`action`), la temporalite (`timeframe`) et extraire les entites cles (personnes, outils, lieux) via regles Spacy, enrichies par le JSON renvoye par le LLM, avec post-traitement pour conserver les cles canoniques (`items`, `id`, `type`, etc.).

### Mod√®le de donn√©es et vectorisation
- Nouvelle collection `memory_preferences` (Chroma/Qdrant) avec cl√© composite `{user_sub, topic, type}`.
- M√©tadonn√©es stock√©es avec chaque vecteur :
  - `type` (`preference` | `intent` | `constraint`)
  - `topic` (cha√Æne normalis√©e)
  - `action` (verbe √† l'infinitif)
  - `timeframe` (ISO 8601 si date reconnue, sinon `ongoing`)
  - `sentiment` (positif, n√©gatif, neutre ‚Äî d√©riv√© du LLM)
  - `confidence` (float 0‚Äì1)
  - `source_message_id` + `thread_id`
  - `captured_at` (UTC ISO timestamp)
- Embedding calcul√© via `text-embedding-3-large` (fallback `text-embedding-004`).
- D√©duplication par `(user_sub, topic, type)` avec fusion pond√©r√©e des scores de confiance.

### Int√©gration dans MemoryGardener
- Ajout d'une √©tape `extract_preference_intent(nodes: list[Message]) -> list[PreferenceRecord]` appel√©e apr√®s `extract_concepts` dans `garden_thread`.
- Injection des nouveaux enregistrements dans la m√™me file de travail que les `mot-code`, en conservant la tra√ßabilit√© via `MemoryEvent(preference_id=...)`.
- Publication d'un √©v√©nement `ws:memory_banner` de type `preference_captured` lorsque la confiance d√©passe 0,6 pour informer l'UI et permettre une confirmation utilisateur.

### Validation et instrumentation
- Corpus d'√©valuation de 100 messages r√©els anonymis√©s + 50 cas synth√©tiques edge-cases pour mesurer pr√©cision (>0,85) et rappel (>0,75).
- Tests unitaires ciblant la d√©duplication et la normalisation (`tests/memory/test_preferences.py`).
- Dashboard Grafana : m√©triques `memory_preferences_captured_total`, `memory_preferences_confidence_bucket`.
- Revue hebdomadaire des extraits captur√©s (√©chantillon al√©atoire de 20) pour ajuster les r√®gles lexicales et le prompt LLM.

---
**Derniere mise a jour** : 2025-10-10 (Phase P2 Sprints 1+2 compl√©t√©s - performance + hints proactifs backend)

**Historique** :
- 2025-10-10 : Phase P2 Sprint 1+2 compl√©t√©s
  - Sprint 1 : Optimisations performance (-71% latence, 100% cache hit rate, fix co√ªts Gemini)
  - Sprint 2 : ProactiveHintEngine backend + int√©gration ChatService (16 tests)
  - Documentation : 3 nouveaux docs status (P2_COMPLETION_FINAL_STATUS.md + 2 sprints)
- 2025-10-09 : Phase P1 compl√©t√©e (MemoryTaskQueue, PreferenceExtractor, 8 m√©triques Prometheus)
- 2025-09-20 : Calibrage vitalit√© + m√©triques decay
- Phase P0 : Persistance cross-device + restauration STM

**R√©f√©rences Phase P2** :
- [P2_COMPLETION_FINAL_STATUS.md](validation/P2_COMPLETION_FINAL_STATUS.md) - R√©sum√© complet
- [P2_SPRINT1_COMPLETION_STATUS.md](validation/P2_SPRINT1_COMPLETION_STATUS.md) - Sprint 1 d√©tails
- [P2_SPRINT2_PROACTIVE_HINTS_STATUS.md](validation/P2_SPRINT2_PROACTIVE_HINTS_STATUS.md) - Sprint 2 d√©tails
- [MEMORY_P2_PERFORMANCE_PLAN.md](optimizations/MEMORY_P2_PERFORMANCE_PLAN.md) - Plan P2 original
