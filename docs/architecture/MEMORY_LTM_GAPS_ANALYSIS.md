# Analyse des Gaps Critiques - M√©moire √† Long Terme (LTM)

**Date** : 2025-10-10
**Agent** : Claude Code
**Phase** : P1.2 - Post-d√©ploiement PreferenceExtractor
**Statut** : üî¥ **CRITIQUE - Action imm√©diate requise**

---

## üìã Vue d'ensemble

Suite au d√©ploiement de la Phase P1 (extraction pr√©f√©rences + d√©portation async), une analyse approfondie r√©v√®le **3 gaps critiques** emp√™chant la m√©moire √† long terme (LTM) de fonctionner correctement.

**Sympt√¥me utilisateur** :
> "Quand je demande aux agents de quoi nous avons parl√© jusqu'√† maintenant, les conversations archiv√©es ne sont jamais √©voqu√©es et les concepts associ√©s ne ressortent pas."

**Cause racine** : Les conversations archiv√©es et les pr√©f√©rences extraites ne sont jamais int√©gr√©es dans ChromaDB (base vectorielle LTM).

---

## üî¥ Gap #1 : Threads archiv√©s JAMAIS consolid√©s dans LTM

### Description du probl√®me

**Workflow actuel** :
```
1. Utilisateur archive une conversation
   ‚îî‚îÄ> UPDATE threads SET archived = 1, archival_reason = 'user_request'

2. Consolidation m√©moire (tend-garden)
   ‚îî‚îÄ> queries.get_threads(include_archived=False)  ‚Üê PAR D√âFAUT !
   ‚îî‚îÄ> R√©cup√®re uniquement threads actifs (archived = 0)

3. Extraction concepts
   ‚îî‚îÄ> Analyse uniquement conversations actives
   ‚îî‚îÄ> Threads archiv√©s IGNOR√âS

4. ChromaDB (LTM)
   ‚îî‚îÄ> Ne contient JAMAIS les concepts des threads archiv√©s
   ‚îî‚îÄ> Recherche vectorielle incompl√®te
```

### Preuves dans le code

**1. Filtre par d√©faut exclut archiv√©s** ([queries.py](../../src/backend/core/database/queries.py))
```python
async def get_threads(
    db: DatabaseManager,
    session_id: str,
    user_id: Optional[str] = None,
    type_: Optional[str] = None,
    include_archived: bool = False,  # ‚Üê PAR D√âFAUT FALSE
    archived_only: bool = False,
    limit: int = 20,
    offset: int = 0,
) -> List[Dict[str, Any]]:
    # ...
    if archived_only:
        clauses.append("archived = 1")
    elif not include_archived:
        clauses.append("archived = 0")  # ‚Üê THREADS ARCHIV√âS EXCLUS
```

**2. Consolidation batch ignore threads** ([gardener.py:tend_the_garden](../../src/backend/features/memory/gardener.py))
```python
async def tend_the_garden(
    self,
    consolidation_limit: int = 10,
    thread_id: Optional[str] = None,
    session_id: Optional[str] = None,
    agent_id: Optional[str] = None,
    user_id: Optional[str] = None,
) -> Dict[str, Any]:
    # Mode thread unique : OK, peut traiter archiv√©s si thread_id fourni
    if thread_id:
        return await self._tend_single_thread(...)

    # Mode batch : PROBL√àME - utilise sessions, pas threads
    sessions = await self._fetch_recent_sessions(
        limit=consolidation_limit, user_id=user_id
    )
    # ‚Üê Ne traite JAMAIS les threads directement
    # ‚Üê Sessions archiv√©es probablement aussi ignor√©es
```

### Impact utilisateur

| Sc√©nario | Comportement actuel | Comportement attendu |
|----------|---------------------|----------------------|
| User archive conversation "Projet Python" | Thread archiv√© ‚Üí Concepts JAMAIS consolid√©s | Thread archiv√© ‚Üí Consolidation imm√©diate ‚Üí Concepts dans LTM |
| User demande "De quoi avons-nous parl√© sur Python ?" | ‚ùå Aucun r√©sultat (concepts absents de ChromaDB) | ‚úÖ Rappel concepts de la conversation archiv√©e |
| User rouvre conversation archiv√©e | ‚úÖ Messages disponibles (SQLite) mais ‚ùå Aucun contexte LTM | ‚úÖ Messages + contexte LTM enrichi |

### M√©triques manquantes

- **Taux archivage** : Combien de threads archiv√©s par utilisateur ?
- **Coverage LTM** : % threads consolid√©s vs total threads
- **Latence consolidation archivage** : Temps entre archivage et int√©gration LTM

---

## üî¥ Gap #2 : Pr√©f√©rences extraites mais JAMAIS persist√©es

### Description du probl√®me

**Workflow actuel** :
```
1. Consolidation m√©moire d√©clench√©e
   ‚îî‚îÄ> MemoryAnalyzer.analyze_session_async()

2. PreferenceExtractor appel√©
   ‚îî‚îÄ> Extraction r√©ussie (filtrage lexical + LLM)
   ‚îî‚îÄ> Pr√©f√©rences identifi√©es avec confidence > 0.6

3. Logging uniquement
   ‚îî‚îÄ> logger.debug(f"Extracted {len(preferences)} preferences")
   ‚îî‚îÄ> # TODO P1.2: Sauvegarder dans Firestore collection memory_preferences_{user_sub}
   ‚îî‚îÄ> ‚ùå STOP ICI - Jamais sauvegard√©

4. ChromaDB
   ‚îî‚îÄ> Aucune pr√©f√©rence dans la collection emergence_knowledge
   ‚îî‚îÄ> _fetch_active_preferences() retourne TOUJOURS vide
```

**Code probl√©matique** ([analyzer.py:386](../../src/backend/features/memory/analyzer.py#L386)) :
```python
if preferences:
    logger.info(
        f"[PreferenceExtractor] Extracted {len(preferences)} preferences/intents "
        f"for session {session_id}"
    )
    # TODO P1.2: Sauvegarder dans Firestore collection memory_preferences_{user_sub}
    # Pour l'instant, juste logger
    for pref in preferences:
        logger.debug(
            f"  [{pref.type}] {pref.topic}: {pref.text[:60]}... "
            f"(confidence={pref.confidence:.2f})"
        )
    # ‚ùå PAS DE SAUVEGARDE ICI
else:
    logger.debug(f"[PreferenceExtractor] No preferences found in session {session_id}")
```

### Architecture attendue vs r√©elle

**Architecture attendue** :
```
PreferenceExtractor ‚Üí ChromaDB (emergence_knowledge)
                      ‚îú‚îÄ type: "preference"
                      ‚îú‚îÄ user_id: "user_123"
                      ‚îú‚îÄ confidence: 0.85
                      ‚îú‚îÄ topic: "programming_languages"
                      ‚îî‚îÄ text: "Je pr√©f√®re Python pour le scripting"

MemoryContextBuilder ‚Üí _fetch_active_preferences()
                      ‚îî‚îÄ> WHERE user_id=X AND type="preference" AND confidence >= 0.6
                      ‚îî‚îÄ> Injection contexte RAG
```

**Architecture r√©elle** :
```
PreferenceExtractor ‚Üí Logger.debug()  ‚ùå PERDU

MemoryContextBuilder ‚Üí _fetch_active_preferences()
                      ‚îî‚îÄ> WHERE user_id=X AND type="preference" AND confidence >= 0.6
                      ‚îî‚îÄ> ‚ùå Toujours vide (aucune donn√©e dans ChromaDB)
```

### Preuve : Code de r√©cup√©ration existe mais inutile

[memory_ctx.py:112-138](../../src/backend/features/chat/memory_ctx.py#L112-L138) :
```python
def _fetch_active_preferences(self, collection, user_id: str) -> str:
    """Fetch active preferences with high confidence (>0.6) for immediate injection."""
    try:
        where = {
            "$and": [
                {"user_id": user_id},
                {"type": "preference"},
                {"confidence": {"$gte": 0.6}},
            ]
        }
        got = collection.get(where=where, include=["documents", "metadatas"])
        docs = got.get("documents", []) or []

        if not docs:
            return ""  # ‚Üê TOUJOURS ICI car aucune donn√©e

        # Ce code n'est JAMAIS ex√©cut√©
        prefs = []
        for doc in docs[:5]:
            if doc and doc.strip():
                prefs.append(f"- {doc.strip()}")

        return "\n".join(prefs) if prefs else ""
    except Exception as e:
        logger.debug(f"_fetch_active_preferences: {e}")
        return ""
```

### Impact utilisateur

| Sc√©nario | Comportement actuel | Comportement attendu |
|----------|---------------------|----------------------|
| User dit "Je pr√©f√®re Python √† JavaScript" | ‚úÖ Extrait (logs) ‚ùå Perdu | ‚úÖ Extrait ‚Üí Sauvegard√© ‚Üí Rappel√© |
| User demande conseil langage | ‚ùå Agent propose JS (pr√©f√©rence ignor√©e) | ‚úÖ Agent rappelle "Tu pr√©f√®res Python" |
| User revient 2 jours apr√®s | ‚ùå Pr√©f√©rences oubli√©es | ‚úÖ Pr√©f√©rences r√©inject√©es automatiquement |

### M√©triques Prometheus inutiles

Les 5 m√©triques P1 sont expos√©es mais **ne peuvent jamais augmenter** en production :
```python
memory_preferences_extracted_total  # ‚Üê Incr√©ment√© lors extraction
memory_preferences_confidence       # ‚Üê Histogram scores
# ...mais aucune donn√©e persist√©e, donc pas d'impact r√©el
```

---

## üü° Gap #3 : Architecture hybride Session vs Thread incoh√©rente

### Description du probl√®me

Le syst√®me utilise **deux architectures de donn√©es** incompatibles :

**1. Architecture legacy (Sessions)** :
```sql
CREATE TABLE sessions (
    id TEXT PRIMARY KEY,
    user_id TEXT,
    session_data TEXT,              -- ‚Üê JSON historique messages
    summary TEXT,                   -- ‚Üê R√©sum√© analyse
    extracted_concepts TEXT,        -- ‚Üê Concepts extraits
    extracted_entities TEXT,        -- ‚Üê Entit√©s extraites
    created_at TEXT,
    updated_at TEXT
);
```

**2. Architecture moderne (Threads v6)** :
```sql
CREATE TABLE threads (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL,
    user_id TEXT NOT NULL,
    type TEXT CHECK(type IN ('chat','debate')),
    title TEXT,
    archived INTEGER DEFAULT 0,     -- ‚Üê Flag archivage
    archival_reason TEXT,
    message_count INTEGER DEFAULT 0,
    created_at TEXT,
    updated_at TEXT
);

CREATE TABLE messages (
    id TEXT PRIMARY KEY,
    thread_id TEXT NOT NULL,
    role TEXT,
    content TEXT,
    created_at TEXT,
    FOREIGN KEY (thread_id) REFERENCES threads(id)
);
```

### Incoh√©rences constat√©es

| Op√©ration | Architecture utilis√©e | Probl√®me |
|-----------|----------------------|----------|
| **Consolidation batch** (`tend_the_garden` sans `thread_id`) | ‚ùå Sessions | Ignore tous les threads modernes |
| **Consolidation thread unique** (`tend_the_garden` avec `thread_id`) | ‚úÖ Threads + Messages | Fonctionne mais jamais appel√© en batch |
| **Stockage concepts** | ‚úÖ ChromaDB (sessions.extracted_concepts legacy) | Pas de lien direct avec threads |
| **R√©cup√©ration contexte** | ‚úÖ ChromaDB (user_id filter) | Fonctionne mais base incompl√®te |

### Code probl√©matique

**Consolidation batch utilise sessions** ([gardener.py](../../src/backend/features/memory/gardener.py)) :
```python
async def tend_the_garden(self, ...):
    # ...
    sessions = await self._fetch_recent_sessions(
        limit=consolidation_limit, user_id=user_id
    )
    # ‚Üê R√©cup√®re table SESSIONS, pas THREADS

    for s in sessions:
        history = self._extract_history(s.get("session_data"))
        # ‚Üê session_data = JSON legacy, pas messages table
```

**Consolidation thread unique utilise architecture moderne** :
```python
async def _tend_single_thread(self, thread_id: str, ...):
    msgs = await queries.get_messages(
        self.db, thread_id, session_id=sid, user_id=uid, limit=1000
    )
    # ‚Üê Utilise table MESSAGES moderne ‚úÖ

    history = []
    for m in msgs:
        history.append({"role": m.get("role"), "content": m.get("content")})
```

### Impact

- **Nouvelles conversations (threads)** : Consolid√©es uniquement si `thread_id` fourni explicitement
- **Anciennes sessions** : Consolid√©es en batch mais format legacy
- **Threads archiv√©s** : Jamais consolid√©s (double peine : architecture moderne + filtre archived)

---

## üéØ Solutions - Plan d'Action Prioris√©

### **Phase 1 : P1 - Persistance pr√©f√©rences (Impact imm√©diat, faible risque)**

**Pourquoi commencer par P1 ?**
1. ‚úÖ **Ind√©pendant** des autres gaps (pas de d√©pendance)
2. ‚úÖ **Impact imm√©diat** : Pr√©f√©rences utilisables d√®s prochaine consolidation
3. ‚úÖ **Tests existants** : 8/8 tests PreferenceExtractor passent
4. ‚úÖ **Code infrastructure ready** : `VectorService.add_documents()` existe
5. ‚úÖ **Faible risque** : Ajout de donn√©es, pas de modification workflow

**Changements requis** :

1. **Modifier `analyzer.py:386-402`** pour sauvegarder pr√©f√©rences
   ```python
   # AVANT (analyzer.py:386)
   # TODO P1.2: Sauvegarder dans Firestore collection memory_preferences_{user_sub}
   for pref in preferences:
       logger.debug(f"  [{pref.type}] {pref.topic}: {pref.text[:60]}...")

   # APR√àS
   await self._save_preferences_to_vector_db(
       preferences=preferences,
       user_id=user_sub,
       thread_id=thread_id,
       session_id=session_id
   )
   ```

2. **Cr√©er m√©thode `_save_preferences_to_vector_db()`**
   - Utiliser `VectorService.add_documents()`
   - Format m√©tadonn√©es compatible `_fetch_active_preferences()`
   - Gestion erreurs gracieuse (fallback si ChromaDB down)

3. **M√©tadonn√©es ChromaDB** :
   ```python
   {
       "user_id": user_sub,
       "type": pref.type,  # "preference" | "intent" | "constraint"
       "topic": pref.topic,
       "confidence": pref.confidence,
       "created_at": datetime.now(timezone.utc).isoformat(),
       "thread_id": thread_id,
       "session_id": session_id,
       "source": "preference_extractor_v1.2"
   }
   ```

4. **Tests** :
   - Test sauvegarde apr√®s extraction
   - Test r√©cup√©ration via `_fetch_active_preferences()`
   - Test workflow end-to-end : extraction ‚Üí sauvegarde ‚Üí r√©injection contexte

**Fichiers impact√©s** :
- ‚úèÔ∏è `src/backend/features/memory/analyzer.py` (+40 lignes)
- ‚úèÔ∏è `tests/backend/features/test_memory_preferences_persistence.py` (nouveau, ~150 lignes)

**Dur√©e estim√©e** : 45-60 min

---

### **Phase 2 : P0 - Consolidation threads archiv√©s (Impact majeur, risque mod√©r√©)**

**Pourquoi apr√®s P1 ?**
1. ‚ö†Ô∏è **Risque mod√©r√©** : Modification workflow consolidation existant
2. üì¶ **D√©pendances** : Requiert tests approfondis (charge, performance)
3. üéØ **Impact majeur** : R√©sout le probl√®me principal utilisateur

**Changements requis** :

1. **Cr√©er endpoint d√©di√©** `POST /api/memory/consolidate-archived`
   ```python
   @router.post("/consolidate-archived")
   async def consolidate_archived_threads(
       request: Request,
       data: Dict[str, Any] = Body(default={})
   ) -> Dict[str, Any]:
       """
       Consolide tous les threads archiv√©s non encore trait√©s.
       Utile pour migration ou rattrapage batch.
       """
       user_id = await get_user_id(request)

       # R√©cup√©rer tous threads archiv√©s
       threads = await queries.get_threads(
           db, session_id=session_id, user_id=user_id,
           archived_only=True, limit=100
       )

       # Consolider chaque thread
       for thread in threads:
           await gardener._tend_single_thread(
               thread_id=thread["id"],
               session_id=thread["session_id"],
               user_id=thread["user_id"]
           )

       return {"status": "success", "consolidated_count": len(threads)}
   ```

2. **Ajouter hook lors archivage** dans `PATCH /api/threads/{id}`
   ```python
   @router.patch("/{thread_id}")
   async def update_thread(thread_id: str, payload: ThreadUpdate, ...):
       # ... update thread ...

       # Si archivage demand√©, d√©clencher consolidation async
       if payload.archived and not thread.get("archived"):
           from backend.features.memory.task_queue import get_memory_queue
           queue = get_memory_queue()
           await queue.enqueue(
               task_type="consolidate_thread",
               payload={"thread_id": thread_id, "reason": "archiving"}
           )

       return {"thread": thread}
   ```

3. **Modifier `tend_the_garden()` mode batch** pour inclure threads
   ```python
   # Option 1 : Ajouter flag include_archived
   async def tend_the_garden(
       self,
       consolidation_limit: int = 10,
       include_archived: bool = False,  # ‚Üê NOUVEAU
       ...
   ):
       threads = await queries.get_threads(
           db, user_id=user_id,
           include_archived=include_archived,  # ‚Üê Pass√© au query
           limit=consolidation_limit
       )
       # Traiter threads directement au lieu de sessions

   # Option 2 : Mode s√©par√© pour migration
   async def consolidate_all_archived_threads(self, user_id: str):
       """Migration one-shot : consolider tous archiv√©s."""
       pass
   ```

4. **Tests** :
   - Test consolidation thread archiv√©
   - Test hook archivage ‚Üí consolidation async
   - Test endpoint `/consolidate-archived`
   - Test performance (100+ threads archiv√©s)

**Fichiers impact√©s** :
- ‚úèÔ∏è `src/backend/features/memory/router.py` (+60 lignes)
- ‚úèÔ∏è `src/backend/features/memory/gardener.py` (+80 lignes)
- ‚úèÔ∏è `src/backend/features/threads/router.py` (+15 lignes)
- ‚úèÔ∏è `src/backend/features/memory/task_queue.py` (+30 lignes)
- ‚úèÔ∏è `tests/backend/features/test_memory_archived_consolidation.py` (nouveau, ~200 lignes)

**Dur√©e estim√©e** : 90-120 min

---

### **Phase 3 : P2 - Harmonisation Session/Thread (Refactoring, risque √©lev√©)**

**Pourquoi en dernier ?**
1. üöß **Risque √©lev√©** : Refactoring majeur workflow consolidation
2. üìã **D√©cision strat√©gique** : Migrer vers threads ou maintenir hybride ?
3. üîÑ **D√©pendances** : Requiert validation architecture compl√®te

**Options strat√©giques** :

**Option A : Migration compl√®te vers Threads**
- Supprimer utilisation `sessions.session_data` (JSON legacy)
- Migrer `tend_the_garden()` pour utiliser uniquement `threads` + `messages`
- Avantages : Architecture coh√©rente, performance am√©lior√©e
- Risques : Breaking changes, migration donn√©es existantes

**Option B : Maintenir hybride avec sync explicite**
- Conserver sessions pour r√©trocompatibilit√©
- Ajouter sync bidirectionnel `sessions.extracted_concepts` ‚Üî `threads`
- Avantages : Pas de breaking changes
- Risques : Complexit√© accrue, dette technique

**Recommandation** : **Reporter apr√®s P0/P1**, d√©cision FG requise.

---

## üìä M√©triques de succ√®s

### M√©triques Phase 1 (P1 - Pr√©f√©rences)

| M√©trique | Baseline (avant) | Target (apr√®s) | Outil mesure |
|----------|------------------|----------------|--------------|
| Pr√©f√©rences persist√©es | 0 | > 80% extraites | Prometheus `memory_preferences_extracted_total` |
| Pr√©f√©rences r√©inject√©es contexte | 0% | > 60% confidence >= 0.6 | Logs `[MemoryContextBuilder] Injected X preferences` |
| Latence sauvegarde | N/A | < 200ms | Prometheus `memory_preferences_extraction_duration_seconds` |

### M√©triques Phase 2 (P0 - Threads archiv√©s)

| M√©trique | Baseline (avant) | Target (apr√®s) | Outil mesure |
|----------|------------------|----------------|--------------|
| Threads archiv√©s consolid√©s | 0% | 100% | SQL `SELECT COUNT(*) FROM threads WHERE archived=1` vs ChromaDB |
| Latence consolidation archivage | N/A | < 5s (async) | Logs `MemoryTaskQueue` |
| Concepts LTM par utilisateur | Variable | +30% (archiv√©s inclus) | ChromaDB count by user_id |

---

## üîß Commandes validation

### V√©rifier pr√©f√©rences dans ChromaDB

```python
# Apr√®s impl√©mentation P1
from backend.features.memory.vector_service import VectorService

vs = VectorService()
collection = vs.get_or_create_collection("emergence_knowledge")

# Requ√™te pr√©f√©rences user
results = collection.get(
    where={
        "$and": [
            {"user_id": "user_123"},
            {"type": "preference"}
        ]
    },
    include=["documents", "metadatas"]
)

print(f"Pr√©f√©rences trouv√©es : {len(results['documents'])}")
```

### V√©rifier threads archiv√©s non consolid√©s

```sql
-- Threads archiv√©s
SELECT COUNT(*) as archived_threads
FROM threads
WHERE archived = 1;

-- Comparer avec ChromaDB (manual check)
-- ‚Üí Si archived_threads > ChromaDB documents with thread_id in archived list
-- ‚Üí Gap de consolidation
```

### Logs consolidation

```bash
# Production logs
gcloud logging read "
  resource.type=cloud_run_revision
  AND severity>=INFO
  AND textPayload=~'\\[PreferenceExtractor\\]|MemoryTaskQueue|tend_single_thread'
" --limit 50 --format json

# Chercher :
# - "[PreferenceExtractor] Extracted X preferences" ‚Üê Extraction OK
# - "Saved X preferences to ChromaDB" ‚Üê Persistance OK (apr√®s P1)
# - "Consolidating archived thread" ‚Üê Archiv√©s OK (apr√®s P0)
```

---

## üìö R√©f√©rences

### Code source

- [analyzer.py](../../src/backend/features/memory/analyzer.py) - MemoryAnalyzer (ligne 386 : TODO pr√©f√©rences)
- [gardener.py](../../src/backend/features/memory/gardener.py) - Consolidation m√©moire
- [memory_ctx.py](../../src/backend/features/chat/memory_ctx.py) - R√©cup√©ration contexte LTM
- [preference_extractor.py](../../src/backend/features/memory/preference_extractor.py) - Extraction pr√©f√©rences
- [queries.py](../../src/backend/core/database/queries.py) - Requ√™tes threads/messages
- [router.py](../../src/backend/features/memory/router.py) - API endpoints m√©moire

### Documentation

- [10-Memoire.md](10-Memoire.md) - Architecture m√©moire (√† cr√©er/mettre √† jour)
- [AGENT_SYNC.md](../../AGENT_SYNC.md) - √âtat session P1 (ligne 199 : hotfix P1.1)
- [passation.md](../passation.md) - Logs sessions (3 derni√®res entr√©es)

### Tests

- [test_memory_enhancements.py](../../tests/backend/features/test_memory_enhancements.py) - Tests pr√©f√©rences existants
- Tests √† cr√©er : `test_memory_preferences_persistence.py`, `test_memory_archived_consolidation.py`

---

## ‚úÖ Checklist validation

**Avant impl√©mentation** :
- [x] Gaps identifi√©s et document√©s
- [x] Priorit√©s √©tablies (P1 ‚Üí P0 ‚Üí P2)
- [x] Plan d'action d√©taill√©
- [ ] Validation FG des priorit√©s
- [ ] Cr√©ation branche `fix/ltm-gaps-p1-p0`

**Phase 1 (P1 - Pr√©f√©rences)** :
- [ ] M√©thode `_save_preferences_to_vector_db()` impl√©ment√©e
- [ ] Tests unitaires persistance (3+ tests)
- [ ] Tests int√©gration end-to-end
- [ ] Validation locale (backend + ChromaDB)
- [ ] M√©triques Prometheus v√©rifi√©es
- [ ] Commit + push branche

**Phase 2 (P0 - Threads archiv√©s)** :
- [ ] Endpoint `/consolidate-archived` cr√©√©
- [ ] Hook archivage ‚Üí consolidation async
- [ ] Tests consolidation archiv√©s (5+ tests)
- [ ] Tests performance (100+ threads)
- [ ] Validation locale migration archiv√©s
- [ ] Commit + push branche

**D√©ploiement** :
- [ ] Merge branche ‚Üí main
- [ ] Build image Docker
- [ ] Deploy Cloud Run (canary 10% ‚Üí 100%)
- [ ] V√©rification logs production
- [ ] Validation m√©triques Prometheus
- [ ] Documentation passation.md mise √† jour

---

**Prochaine action** : Attendre validation FG puis commencer impl√©mentation P1 (persistance pr√©f√©rences).
