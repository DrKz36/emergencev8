# src/backend/features/memory/analyzer.py
# V3.6 - Phase 3: M√©triques Prometheus pour monitoring performance
import logging
import hashlib
from typing import Dict, Any, List, Optional, TYPE_CHECKING, Callable
from datetime import datetime, timedelta

if TYPE_CHECKING:
    from backend.features.chat.service import ChatService
    from backend.core.database.manager import DatabaseManager

from backend.core.database import queries

# ‚ö° M√©triques Prometheus (Phase 3)
try:
    from prometheus_client import Counter, Histogram, Gauge

    # Compteurs succ√®s/√©chec par provider
    ANALYSIS_SUCCESS_TOTAL = Counter(
        "memory_analysis_success_total",
        "Nombre total d'analyses r√©ussies",
        ["provider"]  # neo_analysis, nexus, anima
    )
    ANALYSIS_FAILURE_TOTAL = Counter(
        "memory_analysis_failure_total",
        "Nombre total d'analyses √©chou√©es",
        ["provider", "error_type"]
    )

    # Cache metrics
    CACHE_HITS_TOTAL = Counter(
        "memory_analysis_cache_hits_total",
        "Nombre total de cache hits"
    )
    CACHE_MISSES_TOTAL = Counter(
        "memory_analysis_cache_misses_total",
        "Nombre total de cache misses"
    )
    CACHE_SIZE = Gauge(
        "memory_analysis_cache_size",
        "Taille actuelle du cache in-memory"
    )

    # Latence analyses
    ANALYSIS_DURATION_SECONDS = Histogram(
        "memory_analysis_duration_seconds",
        "Dur√©e des analyses m√©moire",
        ["provider"],
        buckets=[0.5, 1.0, 2.0, 4.0, 6.0, 10.0, 15.0, 20.0, 30.0]
    )

    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False

logger = logging.getLogger(__name__)

if not PROMETHEUS_AVAILABLE:
    logger.warning("Prometheus client non disponible - m√©triques d√©sactiv√©es")

# ‚ö° Cache in-memory pour analyses (TTL 1h)
_ANALYSIS_CACHE: Dict[str, tuple[Dict[str, Any], datetime]] = {}

ANALYSIS_PROMPT_TEMPLATE = """
Analyse la conversation suivante et extrais les informations cl√©s.
La conversation est un dialogue entre un utilisateur ("user") et un ou plusieurs assistants IA ("assistant").

CONVERSATION:
---
{conversation_text}
---

En te basant sur cette conversation, fournis les √©l√©ments suivants :
1.  **summary**: Un r√©sum√© concis de la conversation en 2-3 phrases maximum.
2.  **concepts**: Une liste de 3 √† 5 concepts ou th√®mes principaux abord√©s. Sois sp√©cifique (ex: "√©thique de l'IA dans le diagnostic m√©dical" plut√¥t que "IA").
3.  **entities**: Une liste des noms propres, lieux, ou titres d'≈ìuvres sp√©cifiques mentionn√©s.
"""

ANALYSIS_JSON_SCHEMA = {
    "type": "object",
    "properties": {
        "summary": {
            "type": "string",
            "description": "R√©sum√© concis de la conversation (2-3 phrases).",
        },
        "concepts": {
            "type": "array",
            "items": {"type": "string"},
            "description": "3 √† 5 concepts cl√©s.",
        },
        "entities": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Entit√©s nomm√©es.",
        },
    },
    "required": ["summary", "concepts", "entities"],
}


class MemoryAnalyzer:
    """Analyse s√©mantique de session: summary + concepts + entities (STM)"""

    def __init__(
        self,
        db_manager: "DatabaseManager",
        chat_service: Optional["ChatService"] = None,
    ):
        self.db_manager = db_manager
        self.chat_service = chat_service
        self.is_ready = self.chat_service is not None
        logger.info(f"MemoryAnalyzer V3.4 initialis√©. Pr√™t: {self.is_ready}")

    def set_chat_service(self, chat_service: "ChatService"):
        self.chat_service = chat_service
        self.is_ready = True
        logger.info("ChatService inject√© dans MemoryAnalyzer. L'analyseur est pr√™t.")

    def _ensure_ready(self):
        if not self.chat_service:
            self.is_ready = False
            logger.error(
                "D√©pendance 'chat_service' non inject√©e. L'analyse est impossible."
            )
            raise ReferenceError(
                "MemoryAnalyzer n'est pas pr√™t : chat_service manquant."
            )
        self.is_ready = True

    async def _notify(self, session_id: str, payload: Dict[str, Any]) -> None:
        conn = getattr(
            getattr(self.chat_service, "session_manager", None),
            "connection_manager",
            None,
        )
        if conn:
            try:
                await conn.send_personal_message(
                    {"type": "ws:analysis_status", "payload": payload}, session_id
                )
            except Exception:
                pass

    def _already_analyzed(self, session_id: str) -> bool:
        chat_service = self.chat_service
        if chat_service is None:
            return False
        session_manager = getattr(chat_service, "session_manager", None)
        if session_manager is None:
            return False
        try:
            sess = session_manager.get_session(session_id)
            meta = getattr(sess, "metadata", None) or {}
            summary_value = meta.get("summary")
            return isinstance(summary_value, str) and bool(summary_value.strip())
        except Exception:
            return False

    async def _analyze(
        self,
        session_id: str,
        history: List[Dict[str, Any]],
        persist: bool = True,
        force: bool = False,
    ) -> Dict[str, Any]:
        self._ensure_ready()
        chat_service = self.chat_service
        if chat_service is None:
            raise ReferenceError(
                "MemoryAnalyzer n'est pas pr√™t : chat_service manquant."
            )
        logger.info(
            f"Lancement de l'analyse s√©mantique (persist={persist}) pour {session_id}"
        )

        # Idempotence seulement si on persiste (session r√©elle)
        if persist and not force and self._already_analyzed(session_id):
            logger.info(f"Session {session_id} d√©j√† analys√©e ‚Äî skip.")
            await self._notify(
                session_id,
                {
                    "session_id": session_id,
                    "status": "skipped",
                    "reason": "already_analyzed",
                },
            )
            return {}

        conversation_text = "\n".join(
            f"{m.get('role')}: {m.get('content') or m.get('message', '')}"
            for m in (history or [])
        )
        if not conversation_text.strip():
            logger.warning(f"Historique vide pour {session_id}. Analyse annul√©e.")
            await self._notify(
                session_id,
                {"session_id": session_id, "status": "skipped", "reason": "no_history"},
            )
            return {}

        prompt = ANALYSIS_PROMPT_TEMPLATE.format(conversation_text=conversation_text)

        # ‚ö° Cache Layer: √©viter recalculs inutiles
        cache_key = None
        if persist and not force:
            history_hash = hashlib.md5(conversation_text.encode()).hexdigest()[:8]
            cache_key = f"memory_analysis:{session_id}:{history_hash}"

            # Check cache validity (TTL 1h)
            if cache_key in _ANALYSIS_CACHE:
                cached_data, cached_at = _ANALYSIS_CACHE[cache_key]
                if datetime.now() - cached_at < timedelta(hours=1):
                    logger.info(f"[MemoryAnalyzer] Cache HIT pour session {session_id} (hash={history_hash})")
                    # üìä M√©trique cache HIT
                    if PROMETHEUS_AVAILABLE:
                        CACHE_HITS_TOTAL.inc()
                    return cached_data
                else:
                    # Cache expir√©
                    del _ANALYSIS_CACHE[cache_key]
                    logger.debug(f"[MemoryAnalyzer] Cache EXPIRED pour session {session_id}")

        # üìä M√©trique cache MISS
        if PROMETHEUS_AVAILABLE and persist and not force:
            CACHE_MISSES_TOTAL.inc()

        analysis_result: Dict[str, Any] = {}
        primary_error: Optional[Exception] = None
        provider_used = "neo_analysis"
        start_time = datetime.now()

        # Tentative primaire : neo_analysis (GPT-4o-mini - rapide pour JSON)
        try:
            analysis_result = await chat_service.get_structured_llm_response(
                agent_id="neo_analysis", prompt=prompt, json_schema=ANALYSIS_JSON_SCHEMA
            )
            # üìä M√©triques succ√®s
            if PROMETHEUS_AVAILABLE:
                duration = (datetime.now() - start_time).total_seconds()
                ANALYSIS_DURATION_SECONDS.labels(provider="neo_analysis").observe(duration)
                ANALYSIS_SUCCESS_TOTAL.labels(provider="neo_analysis").inc()
            logger.info(f"[MemoryAnalyzer] Analyse r√©ussie avec neo_analysis pour session {session_id}")
        except Exception as e:
            primary_error = e
            error_type = type(e).__name__
            # üìä M√©triques √©chec
            if PROMETHEUS_AVAILABLE:
                ANALYSIS_FAILURE_TOTAL.labels(provider="neo_analysis", error_type=error_type).inc()
            logger.warning(
                f"[MemoryAnalyzer] Analyse neo_analysis √©chou√©e ({error_type}) pour session {session_id} ‚Äî fallback Nexus",
                exc_info=True,
            )

        # Fallback 1 : Nexus (Anthropic - plus fiable)
        if not analysis_result:
            provider_used = "nexus"
            start_time = datetime.now()
            try:
                analysis_result = await chat_service.get_structured_llm_response(
                    agent_id="nexus", prompt=prompt, json_schema=ANALYSIS_JSON_SCHEMA
                )
                # üìä M√©triques succ√®s Nexus
                if PROMETHEUS_AVAILABLE:
                    duration = (datetime.now() - start_time).total_seconds()
                    ANALYSIS_DURATION_SECONDS.labels(provider="nexus").observe(duration)
                    ANALYSIS_SUCCESS_TOTAL.labels(provider="nexus").inc()
                logger.info(f"[MemoryAnalyzer] Fallback Nexus r√©ussi pour session {session_id}")
            except Exception as e:
                # üìä M√©triques √©chec Nexus
                if PROMETHEUS_AVAILABLE:
                    ANALYSIS_FAILURE_TOTAL.labels(provider="nexus", error_type=type(e).__name__).inc()
                logger.warning(f"[MemoryAnalyzer] Fallback Nexus √©chou√© ({type(e).__name__}) ‚Äî tentative Anima", exc_info=True)

                # Fallback 2 : Anima (OpenAI - derni√®re chance)
                provider_used = "anima"
                start_time = datetime.now()
                try:
                    analysis_result = await chat_service.get_structured_llm_response(
                        agent_id="anima", prompt=prompt, json_schema=ANALYSIS_JSON_SCHEMA
                    )
                    # üìä M√©triques succ√®s Anima
                    if PROMETHEUS_AVAILABLE:
                        duration = (datetime.now() - start_time).total_seconds()
                        ANALYSIS_DURATION_SECONDS.labels(provider="anima").observe(duration)
                        ANALYSIS_SUCCESS_TOTAL.labels(provider="anima").inc()
                    logger.info(f"[MemoryAnalyzer] Fallback Anima r√©ussi pour session {session_id}")
                except Exception as final_error:
                    # üìä M√©triques √©chec Anima
                    if PROMETHEUS_AVAILABLE:
                        ANALYSIS_FAILURE_TOTAL.labels(provider="anima", error_type=type(final_error).__name__).inc()
                    logger.error(
                        f"[MemoryAnalyzer] Tous fallbacks √©chou√©s pour session {session_id}: {final_error}",
                        exc_info=True
                    )
                    retry_after = None
                    try:
                        rd = getattr(primary_error or final_error, "retry_delay", None)
                        retry_after = getattr(rd, "seconds", None)
                    except Exception:
                        pass
                    await self._notify(
                        session_id,
                        {
                            "session_id": session_id,
                            "status": "failed",
                            "error": str(final_error),
                            "retry_after": retry_after,
                        },
                    )
                    raise

        summary_value = str(analysis_result.get("summary", "") or "")
        concepts_raw = analysis_result.get("concepts", []) or []
        entities_raw = analysis_result.get("entities", []) or []
        concepts_value = [str(item) for item in concepts_raw if isinstance(item, str)]
        entities_value = [str(item) for item in entities_raw if isinstance(item, str)]

        if persist:
            await queries.update_session_analysis_data(
                db=self.db_manager,
                session_id=session_id,
                summary=summary_value,
                concepts=concepts_value,
                entities=entities_value,
            )

        try:
            session_manager = getattr(chat_service, "session_manager", None)
            if session_manager:
                session_manager.update_session_metadata(
                    session_id,
                    summary=summary_value,
                    concepts=concepts_value,
                    entities=entities_value,
                )
        except Exception as meta_err:
            logger.debug(
                f"Impossible de mettre √† jour les m√©tadonn√©es de session {session_id}: {meta_err}"
            )

        # ‚ö° Save to cache (apr√®s analyse r√©ussie)
        if analysis_result and cache_key and persist:
            _ANALYSIS_CACHE[cache_key] = (analysis_result, datetime.now())
            logger.info(f"[MemoryAnalyzer] Cache SAVED pour session {session_id} (key={cache_key})")

            # Cleanup: limiter taille cache (max 100 entr√©es)
            if len(_ANALYSIS_CACHE) > 100:
                oldest_key = min(_ANALYSIS_CACHE.keys(), key=lambda k: _ANALYSIS_CACHE[k][1])
                del _ANALYSIS_CACHE[oldest_key]
                logger.debug(f"[MemoryAnalyzer] Cache cleanup: removed oldest entry {oldest_key}")

            # üìä M√©trique taille cache
            if PROMETHEUS_AVAILABLE:
                CACHE_SIZE.set(len(_ANALYSIS_CACHE))

        await self._notify(
            session_id, {"session_id": session_id, "status": "completed", "provider": provider_used}
        )
        logger.info(
            f"Analyse s√©mantique termin√©e (persist={persist}, provider={provider_used}) pour {session_id}."
        )
        return analysis_result

    async def analyze_session_for_concepts(
        self, session_id: str, history: List[Dict[str, Any]], *, force: bool = False
    ):
        """Mode historique (sessions) : persiste dans la table sessions."""
        return await self._analyze(session_id, history, persist=True, force=force)

    async def analyze_history(self, session_id: str, history: List[Dict[str, Any]]):
        """Mode ¬´thread-only¬ª : renvoie le r√©sultat sans √©crire dans la table sessions."""
        return await self._analyze(session_id, history, persist=False, force=False)

    async def analyze_session_async(
        self,
        session_id: str,
        force: bool = False,
        callback: Callable = None
    ) -> None:
        """
        Version asynchrone non-bloquante de analyze_session_for_concepts.
        Enqueue t√¢che dans MemoryTaskQueue.

        Args:
            session_id: ID session √† analyser
            force: Forcer nouvelle analyse
            callback: Fonction appel√©e avec r√©sultat
        """
        from backend.features.memory.task_queue import get_memory_queue

        queue = get_memory_queue()
        await queue.enqueue(
            task_type="analyze",
            payload={"session_id": session_id, "force": force},
            callback=callback
        )

        logger.info(f"Analyse session {session_id} enqueued (async)")
